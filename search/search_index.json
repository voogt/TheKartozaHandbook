{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kartoza Handbook \u00b6 This site comprises the organisational and technical documentation for Kartoza . This is where we highlight the procedures, principles, and processes related to Development, DevOps, and GIS, in line with the organisations best practices. This is open content, available on GitHub and freely licensed as public domain content under the terms of CC0 1.0 Universal . This content is delivered without any warranty, express or implied. Use at own risk. Purpose \u00b6 The purpose and function of this collection of documents is to perform the following: Improve consistency in processes and products Improve efficiency and innovation Increase transparency and accountability Improve value for clients Provide a space for the dissemination and proliferation of ideas Promote a culture of openness and collaboration Provide a single source of truth for resources Promote personal growth and development Add value to the community Scope \u00b6 Kartoza is a company that specializes in Open Source Geospatial solutions. As a result, topics covered by this documentation will be limited to categories relevant to the operations of Kartoza. These categories are outlined as follows: Company : General practices and procedures for Kartoza staff GIS : Resources for Geographic Information Systems and data Development : Software development processes, tools, and conventions DevOps : Developer operations and system administration Resources : Cheatsheets, links, media, and other resources This repository is limited to these categories, with some slight overlap in domain verticals. In the majority of instances, where overlaps with adjacent fields of interest, such as Data Science, \"Big Data\", or to some extent even earth observation and remote sensing, these elements should be primarily remanded to external references in the resources section. Whilst some resources (such as tutorials on Semi-Automated Classification with QGIS) may be considered valuable additions, the priority of this content is to remain a concise collection of resources directly related to the operations and key competencies of Kartoza staff. Limitations \u00b6 This collection of documents does not constitute a replacement for Standard Operating Procedures (SOPs) and company policy. In some cases, our SOPs may point to sections of this handbook, but the SOP itself is canonical as to where the procude content lies. Due to the rate at which modern technology develops, opinions change, project needs or priorities are adjusted, and the operational requirements of the organisation evolve, this collection is somewhat ephemeral and should be considered a dynamic \"living document\" which is subject to constant change and iteration. Processes and documentation from this collection are developed in conjunction with the broader community, independant contractors, temporary staff, juniors, and interns. As such they are not guaranteed to reflect the views of Kartoza, and are not intended to be a substitute for official policy. As resources and processes mature, they may be incorporated into official SOPs as required.","title":"Home"},{"location":"#kartoza-handbook","text":"This site comprises the organisational and technical documentation for Kartoza . This is where we highlight the procedures, principles, and processes related to Development, DevOps, and GIS, in line with the organisations best practices. This is open content, available on GitHub and freely licensed as public domain content under the terms of CC0 1.0 Universal . This content is delivered without any warranty, express or implied. Use at own risk.","title":"Kartoza Handbook"},{"location":"#purpose","text":"The purpose and function of this collection of documents is to perform the following: Improve consistency in processes and products Improve efficiency and innovation Increase transparency and accountability Improve value for clients Provide a space for the dissemination and proliferation of ideas Promote a culture of openness and collaboration Provide a single source of truth for resources Promote personal growth and development Add value to the community","title":"Purpose"},{"location":"#scope","text":"Kartoza is a company that specializes in Open Source Geospatial solutions. As a result, topics covered by this documentation will be limited to categories relevant to the operations of Kartoza. These categories are outlined as follows: Company : General practices and procedures for Kartoza staff GIS : Resources for Geographic Information Systems and data Development : Software development processes, tools, and conventions DevOps : Developer operations and system administration Resources : Cheatsheets, links, media, and other resources This repository is limited to these categories, with some slight overlap in domain verticals. In the majority of instances, where overlaps with adjacent fields of interest, such as Data Science, \"Big Data\", or to some extent even earth observation and remote sensing, these elements should be primarily remanded to external references in the resources section. Whilst some resources (such as tutorials on Semi-Automated Classification with QGIS) may be considered valuable additions, the priority of this content is to remain a concise collection of resources directly related to the operations and key competencies of Kartoza staff.","title":"Scope"},{"location":"#limitations","text":"This collection of documents does not constitute a replacement for Standard Operating Procedures (SOPs) and company policy. In some cases, our SOPs may point to sections of this handbook, but the SOP itself is canonical as to where the procude content lies. Due to the rate at which modern technology develops, opinions change, project needs or priorities are adjusted, and the operational requirements of the organisation evolve, this collection is somewhat ephemeral and should be considered a dynamic \"living document\" which is subject to constant change and iteration. Processes and documentation from this collection are developed in conjunction with the broader community, independant contractors, temporary staff, juniors, and interns. As such they are not guaranteed to reflect the views of Kartoza, and are not intended to be a substitute for official policy. As resources and processes mature, they may be incorporated into official SOPs as required.","title":"Limitations"},{"location":"contributing/","text":"Contributing \u00b6 Although Kartoza is a privately held Open Source development and consulting company, the organisation deeply values transparency, delivery of value to the broader community, and continuous engagement with all stakeholders. Community contributions to this documentation site and associated resources are welcome. Contributions are expected to adhere to the QGIS.org Diversity Statement and Code of Conduct . If you have any queries or feedback, please contact us at info@kartoza.com Conventions \u00b6 The following conventions outline expectations for contributions to this documentation project: Use grammar checking tools where available, such as grammarly or spell checking extensions for your IDE Request a review for internal changes before they are merged into the main repository Default to British English spellings rather than American English Do not commit sensitive information or links to non-public resources. This includes internal unlisted youtube channels, cloud storage repositories such as nextcloud, or personal details Due to the nature of the contents in this repository, when making large edits that do not create new content, communicate with team members to prevent collisions When producing assets such as images, ensure they are the minimum viable size and do not commit large resources to git Assets and media elements such as images are best left out of the source control where possible. Use an external storage system (e.g. minio/ s3), or paste an image into an image to get a GitHub reference to the media item rather than committing to git. This includes screenshots etc. that are likely to change or be updated over time. Use the assets directory to store assets that are not likely to change such as logos When using assets, upload them to a suitable file path according to their primary usage location, e.g. assets/images/resources/cheatsheets/postgresql/joins.png Due to the depth and breadth of these resources, it is necessary to manually index new pages in various subcategories to ensure access and discoverability It makes sense to use a consistent legend of emoji for tagging project and documentation items. Although it may have a steep initial learning curve or implementation strategy, using emoji and unicode symbols to tag elements is a fun and intuitive way to attach metadata to elements which makes visually scanning over documents and commit histories much more effective in multiple languages. Please see the polyglot document for more information. Build and check your changes locally to catch any errors before committing them to the main repository TODO: come up with some formatting guideline (e.g. max line length etc) Tags, Badges, and Shields \u00b6 Tagging elements with emoji is useful for visual identification and search of various elements in broader categories, but sometimes more explicit metadata is required to be attached to something to indicate whether it constitutes a general resource, opinion, community standard, or whether something is a known reference item connected to an official SOP. One method of identifying such features may be using shields.io , for example: ![Best Practice](https://img.shields.io/badge/kartoza-best--practice-blue) ![Community](https://img.shields.io/badge/community-standard-brightgreen) ![Industry](https://img.shields.io/badge/industry-standard-yellowgreen) Translations \u00b6 Due to the scope and intension for frequent updates to this documentation, additional languages will not be supported at this time. Translations and i18n are handled by the documentation framework, as outlined in the mkdocs and mkdocs-material documentation. Framework \u00b6 This documentation uses the mkdocs-material framework, and site configuration is specified in the mkdocs.yaml file. Various extensions are supported to improve usability, such as pymdown , which may be enabled via pull requests. Please note that only extensions which provide relevant value will be considered for integration, and extensions with significant learning curves or duplication should be avoided. Extensions which provide accessibility improvements are welcome. Building \u00b6 The online documentation is built using github actions and published to the gh-pages branch. To build the documentation locally, use the docker command docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material build to populate the site directory with the static content. To serve the data for testing, a simple solution is to use a python webserver to serve the data at 127.0.0.1:9101 using the command cd site && python -m http.server --bind 127.0.0.1 9101 . Note that the generated site data and assets are explicitly excluded from git.","title":"Contributing"},{"location":"contributing/#contributing","text":"Although Kartoza is a privately held Open Source development and consulting company, the organisation deeply values transparency, delivery of value to the broader community, and continuous engagement with all stakeholders. Community contributions to this documentation site and associated resources are welcome. Contributions are expected to adhere to the QGIS.org Diversity Statement and Code of Conduct . If you have any queries or feedback, please contact us at info@kartoza.com","title":"Contributing"},{"location":"contributing/#conventions","text":"The following conventions outline expectations for contributions to this documentation project: Use grammar checking tools where available, such as grammarly or spell checking extensions for your IDE Request a review for internal changes before they are merged into the main repository Default to British English spellings rather than American English Do not commit sensitive information or links to non-public resources. This includes internal unlisted youtube channels, cloud storage repositories such as nextcloud, or personal details Due to the nature of the contents in this repository, when making large edits that do not create new content, communicate with team members to prevent collisions When producing assets such as images, ensure they are the minimum viable size and do not commit large resources to git Assets and media elements such as images are best left out of the source control where possible. Use an external storage system (e.g. minio/ s3), or paste an image into an image to get a GitHub reference to the media item rather than committing to git. This includes screenshots etc. that are likely to change or be updated over time. Use the assets directory to store assets that are not likely to change such as logos When using assets, upload them to a suitable file path according to their primary usage location, e.g. assets/images/resources/cheatsheets/postgresql/joins.png Due to the depth and breadth of these resources, it is necessary to manually index new pages in various subcategories to ensure access and discoverability It makes sense to use a consistent legend of emoji for tagging project and documentation items. Although it may have a steep initial learning curve or implementation strategy, using emoji and unicode symbols to tag elements is a fun and intuitive way to attach metadata to elements which makes visually scanning over documents and commit histories much more effective in multiple languages. Please see the polyglot document for more information. Build and check your changes locally to catch any errors before committing them to the main repository TODO: come up with some formatting guideline (e.g. max line length etc)","title":"Conventions"},{"location":"contributing/#tags-badges-and-shields","text":"Tagging elements with emoji is useful for visual identification and search of various elements in broader categories, but sometimes more explicit metadata is required to be attached to something to indicate whether it constitutes a general resource, opinion, community standard, or whether something is a known reference item connected to an official SOP. One method of identifying such features may be using shields.io , for example: ![Best Practice](https://img.shields.io/badge/kartoza-best--practice-blue) ![Community](https://img.shields.io/badge/community-standard-brightgreen) ![Industry](https://img.shields.io/badge/industry-standard-yellowgreen)","title":"Tags, Badges, and Shields"},{"location":"contributing/#translations","text":"Due to the scope and intension for frequent updates to this documentation, additional languages will not be supported at this time. Translations and i18n are handled by the documentation framework, as outlined in the mkdocs and mkdocs-material documentation.","title":"Translations"},{"location":"contributing/#framework","text":"This documentation uses the mkdocs-material framework, and site configuration is specified in the mkdocs.yaml file. Various extensions are supported to improve usability, such as pymdown , which may be enabled via pull requests. Please note that only extensions which provide relevant value will be considered for integration, and extensions with significant learning curves or duplication should be avoided. Extensions which provide accessibility improvements are welcome.","title":"Framework"},{"location":"contributing/#building","text":"The online documentation is built using github actions and published to the gh-pages branch. To build the documentation locally, use the docker command docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material build to populate the site directory with the static content. To serve the data for testing, a simple solution is to use a python webserver to serve the data at 127.0.0.1:9101 using the command cd site && python -m http.server --bind 127.0.0.1 9101 . Note that the generated site data and assets are explicitly excluded from git.","title":"Building"},{"location":"polyglot/","text":"Polyglot: The Emoji Map \u00b6 Although it may have a steep initial learning curve or implementation strategy, using emoji and unicode symbols to tag elements is a fun and intuitive way to attach metadata to elements which makes visually scanning over documents and commit histories much more effective in multiple languages. In order for this to be effective, a consistent method of referencing the emoji meanings is required. This is challenging because the utilisation of emoji are typically context specific, which requires a mapping of emoji meanings for various contexts. Kartoza values inclusion and diversity. Please contribute to ensure that the items represented here remain inclusive and fair wherever possible. gitmoji \u00b6 Tagging commit messages in git is a useful tool for visually assessing the issues addressed by a particular commit. A community standard has already been developed, available at https://gitmoji.dev/ kitmoji (gitmoji-) \u00b6 gitmoji is fairly comprehensive collection, and used quite widely in the tech community (relative to similar projects). The downside to this is that it is rather verbose and becomes cumbersome to learn and use. The simple solution is to select a subset (kit) of the gitmoji icons and use them as broader higher level categories. This keeps things a bit more consistent and allows gradual adoption of the wider collection. id Icon Reference Function 1 \u2728 :sparkles: New features 2 \ud83d\udc1b :bug: Bugfix 3 \u267b\ufe0f :recycle: Refactoring/ Comments 4 \ud83d\udcdd :memo: Documentation 5 \ud83d\udc84 :lipstick: UI 6 \u26a1\ufe0f :zap: Performance 7 \ud83d\ude80 :rocket: CI/ CD/ Deployment 8 \u2705 :white_check_mark: Testing 9 \ud83d\udd12\ufe0f :lock: Security 10 \ud83d\udd25 :fire: Remove data 11 \u23ea\ufe0f :rewind: Revert changes 12 \u2697\ufe0f / \ud83d\udca9 :alembic: / :poop: Experiments/ PoC/ bad code Not every commit has to have a gitmoji, but it's useful for common cases. GeoMoji \u00b6 As with gitmoji, we need a consistent way to reference Geographic Information Elements. This could be related to data sources, licenses, tools, or standard metadata categories. Some may confuse the concept of geomoji with generic symbology and signage , but in this instance the reference is to a series of common Emoji characters which can be used as concise, visually effective hashtags that can be used across across applications, search tools, git messages, documentation, or social media. It would be great to extend this concept to a collection of map symbols (e.g. using emoji instead of a font library). A alpha-state concept project is in development at https://github.com/zacharlie/geomoji .","title":"Polyglot"},{"location":"polyglot/#polyglot-the-emoji-map","text":"Although it may have a steep initial learning curve or implementation strategy, using emoji and unicode symbols to tag elements is a fun and intuitive way to attach metadata to elements which makes visually scanning over documents and commit histories much more effective in multiple languages. In order for this to be effective, a consistent method of referencing the emoji meanings is required. This is challenging because the utilisation of emoji are typically context specific, which requires a mapping of emoji meanings for various contexts. Kartoza values inclusion and diversity. Please contribute to ensure that the items represented here remain inclusive and fair wherever possible.","title":"Polyglot: The Emoji Map"},{"location":"polyglot/#gitmoji","text":"Tagging commit messages in git is a useful tool for visually assessing the issues addressed by a particular commit. A community standard has already been developed, available at https://gitmoji.dev/","title":"gitmoji"},{"location":"polyglot/#kitmoji-gitmoji-","text":"gitmoji is fairly comprehensive collection, and used quite widely in the tech community (relative to similar projects). The downside to this is that it is rather verbose and becomes cumbersome to learn and use. The simple solution is to select a subset (kit) of the gitmoji icons and use them as broader higher level categories. This keeps things a bit more consistent and allows gradual adoption of the wider collection. id Icon Reference Function 1 \u2728 :sparkles: New features 2 \ud83d\udc1b :bug: Bugfix 3 \u267b\ufe0f :recycle: Refactoring/ Comments 4 \ud83d\udcdd :memo: Documentation 5 \ud83d\udc84 :lipstick: UI 6 \u26a1\ufe0f :zap: Performance 7 \ud83d\ude80 :rocket: CI/ CD/ Deployment 8 \u2705 :white_check_mark: Testing 9 \ud83d\udd12\ufe0f :lock: Security 10 \ud83d\udd25 :fire: Remove data 11 \u23ea\ufe0f :rewind: Revert changes 12 \u2697\ufe0f / \ud83d\udca9 :alembic: / :poop: Experiments/ PoC/ bad code Not every commit has to have a gitmoji, but it's useful for common cases.","title":"kitmoji (gitmoji-)"},{"location":"polyglot/#geomoji","text":"As with gitmoji, we need a consistent way to reference Geographic Information Elements. This could be related to data sources, licenses, tools, or standard metadata categories. Some may confuse the concept of geomoji with generic symbology and signage , but in this instance the reference is to a series of common Emoji characters which can be used as concise, visually effective hashtags that can be used across across applications, search tools, git messages, documentation, or social media. It would be great to extend this concept to a collection of map symbols (e.g. using emoji instead of a font library). A alpha-state concept project is in development at https://github.com/zacharlie/geomoji .","title":"GeoMoji"},{"location":"company/kartoza/","text":"About Kartoza \u00b6 In this section we describe the company, our ethos and general expectations of our team members and their use of technology and systems within the company. All staff members are expected to read and comply with (where applicable) the content laid out in this handbook. Kartoza is a South Africa-based Free and Open Source GIS (FOSSGIS) service provider. We use GIS software to solve complex location-related problems for individuals, businesses and governments around the world. Kartoza was formed as a merger between Linfiniti and Afrispatial. Learn more at our company website https://kartoza.com Strategic Objective Your Kartoza Computer Essential Software","title":"Kartoza"},{"location":"company/kartoza/#about-kartoza","text":"In this section we describe the company, our ethos and general expectations of our team members and their use of technology and systems within the company. All staff members are expected to read and comply with (where applicable) the content laid out in this handbook. Kartoza is a South Africa-based Free and Open Source GIS (FOSSGIS) service provider. We use GIS software to solve complex location-related problems for individuals, businesses and governments around the world. Kartoza was formed as a merger between Linfiniti and Afrispatial. Learn more at our company website https://kartoza.com Strategic Objective Your Kartoza Computer Essential Software","title":"About Kartoza"},{"location":"company/kartoza/deleteme/","text":"How I made my map \u00b6 Getting boundaries \u00b6 https://data.humdata.org/dataset/cod-ab-zaf? I chose this rather than the official SA boundaries because it is recommended Download the shp zip https://data.humdata.org/dataset/061d4492-56e8-458c-a3fb-e7950991adf0/resource/f5b08257-8d03-48dc-92c8-aaa4fb7285f0/download/zaf_adm_sadb_ocha_20201109_shp.zip","title":"How I made my map"},{"location":"company/kartoza/deleteme/#how-i-made-my-map","text":"","title":"How I made my map"},{"location":"company/kartoza/deleteme/#getting-boundaries","text":"https://data.humdata.org/dataset/cod-ab-zaf? I chose this rather than the official SA boundaries because it is recommended Download the shp zip https://data.humdata.org/dataset/061d4492-56e8-458c-a3fb-e7950991adf0/resource/f5b08257-8d03-48dc-92c8-aaa4fb7285f0/download/zaf_adm_sadb_ocha_20201109_shp.zip","title":"Getting boundaries"},{"location":"company/kartoza/essential_software/","text":"Essential Software \u00b6 In this section we will enumerate all of the software packages you should have installed on your computer. There are some items that can be considered optional, but you should be aware of all of these tools and install them when and as the need arises. QGIS \u00b6 URL: Purpose: Notes: Postgresql \u00b6 URL: www.postgresql.org Purpose: Relational database management system with GIS support. Notes: LibreOffice \u00b6 URL: libreoffice.org/ Purpose: Office productivity suite. Notes: Git & GitHub Account \u00b6 URL: github.org Purpose: Version control of digital assets Notes: Although GitHub is not Git, you need to be set up to work on github. \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes: \u00b6 URL: Purpose: Notes:","title":"Essential Software"},{"location":"company/kartoza/essential_software/#essential-software","text":"In this section we will enumerate all of the software packages you should have installed on your computer. There are some items that can be considered optional, but you should be aware of all of these tools and install them when and as the need arises.","title":"Essential Software"},{"location":"company/kartoza/essential_software/#qgis","text":"URL: Purpose: Notes:","title":"QGIS"},{"location":"company/kartoza/essential_software/#postgresql","text":"URL: www.postgresql.org Purpose: Relational database management system with GIS support. Notes:","title":"Postgresql"},{"location":"company/kartoza/essential_software/#libreoffice","text":"URL: libreoffice.org/ Purpose: Office productivity suite. Notes:","title":"LibreOffice"},{"location":"company/kartoza/essential_software/#git--github-account","text":"URL: github.org Purpose: Version control of digital assets Notes: Although GitHub is not Git, you need to be set up to work on github.","title":"Git &amp; GitHub Account"},{"location":"company/kartoza/essential_software/#_1","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_2","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_3","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_4","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_5","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_6","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_7","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_8","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_9","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_10","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_11","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_12","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_13","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_14","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_15","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_16","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/essential_software/#_17","text":"URL: Purpose: Notes:","title":""},{"location":"company/kartoza/operating_principles/","text":"Kartoza's Thirty Principles \u00b6 We are innovative. This means we are not set in our ways. We have a diverse toolset and skills and while we retain combinations that work well, we readily change and adapt these and discard those that don't work. Company decisions conform to the Strategic Objective , these Thirty Principles and Working Procedures documents. We are a lean and agile company and follow SAFe principles. We promote open and easy access to information. We provide opportunities for community involvement. We provide opportunities for education and training in FOSS tools and GISc. Our internal systems and client-facing solutions are scalable, resilient and reliable. We are the highest-quality spatial IT company in South Africa and equal to the best globally. We do whatever it takes to ensure the quality of service to our clients, employees and suppliers is impeccable. We draw solid lines, thus providing an exact status of where things stand. Documented procedures are the main defence against grey-area problems. \"Get the job done.\" Can the employee do his or her job, or is there always a complication of one kind or another? This ability to \"get the job done quickly and accurately without excuses or complications\" is the most valuable trait an employee can possess. Employees come first. We employ people who have an innate desire to perform at a hundred percent. We reward them accordingly. The natural outcome is that we serve our clients well. We are not fire killers. We are fire prevention specialists. We don't manage problems; we work on system enhancement and system maintenance to prevent problems from happening in the first place. Problems are gifts that inspire us to action. A problem prompts the act of creating or improving a system or procedure. We don't want setbacks, but when one occurs we think, \"thank you for this wake-up call,\" and take assertive system-improvement action to prevent the setback from happening again. We focus on just [[a few manageable markets|Kartoza Portfolio Offerings]]. Although we watch for new opportunities, in the end we provide \"just a few products and services implemented in superb fashion,\" rather than a complex array of average-quality offerings. We find the simplest solution. Ockham's Law, also called the Law of Economy, states, \"Entities are not to be multiplied beyond necessity . . . the simplest solution is invariably the correct solution.\" The money we save or waste is not Monopoly money! We are careful not to devalue the worth of a Rand (or Dollar or Rupiah or Euro) just because it has to do with the business. We operate the company via documented procedures and systems. \"Any recurring problem can be solved with a system.\" We take the necessary time to create and implement systems and procedures and in the end, it is well worth it. If there is a recurring problem, a written procedure is created to prevent the problem from happening again. On the other hand, we don't bog down the organisation with processes and procedures that target once-in-a-while situations. Sometimes we elect to not create a procedure. \"Just don't do it.\" Eliminate the unnecessary. Many times, elimination of a system, protocol, or potential project is a very good thing. Think simplicity. Automate. Refine to the smallest number of steps or discard altogether. Would a simple \"no\" save time, energy or money? Our documented systems, procedures, and functions are \"off-the-street.\" This means anyone with appropriate training can perform procedures unassisted. The real-world evidence of this is we can hire an individual \"off-the-street\" who has good GIS or programming skills and have him or her doing QGIS or development work within a week. For this result, protocols have to be efficient, simple, and thoroughly documented. Do it NOW. All actions build on \"point-of-sale\" theory. We don't delay an action if it can be done immediately. Just like any major retail outlet, we \"update inventories and databases at the exact time the transaction takes place.\" There is no paperwork floating around the office after a physical transaction. We ask, \"How can we perform the task NOW without creating lingering details that we must clean up later?\" We glean the Kartoza mindset from Stephen Covey's books, including The 7 Habits of Highly Successful People, First Things First, and The 8th Habit. As well, we consider Good to Great by Jim Collins; The E-Myth Revisited by Michael Gerber; Awaken the Giant Within by Anthony Robbins; Maverick by Ricardo Semler; Work the System by Sam Carpenter. We pattern individual organisation upon Franklin-Covey theory. We use organising mechanisms that are always at hand. We prioritise, schedule, and document. The system is always up-to-date and we use it all the time. For Kartoza, these are Github, Google Suite (Mail, Drive, etc.), SyncThing, Sage, OpenProject and others (subject to change as of August 2020) Sequence and priority are critical. We work on the most important tasks first. We spend maximum time on \"non-urgent/important\" tasks via Stephen Covey's time-matrix philosophy. We double-check everything before release. If a penchant for double-checking is not an innate personal habit, then it must be cultivated. Double-checking is a conscious step in every task, performed either by the individual managing the task or someone else. Our environment is spotless: clean and ordered, simple, efficient, functional. No \"rat's nests\", literally or figuratively. Employee training is structured, scheduled, and thorough. Assertive client contact is also structured, scheduled, and thorough. We are deadline-obsessed. If someone in the organisation says they will be finished with a task or project by a certain date and time, then he or she commits to finishing by that deadline (or, if legitimate delays intrude, advise coworkers well in advance that the deadline is impossible to meet). We maintain equipment and keep it a hundred percent functional at all times. If something is not working as it should, fix it now even if it's not necessary to fix it now. It's a matter of good housekeeping and of maintaining good habits. This is just the way we do things. Mastery of the English language is critical. We are aware of how we sound and what we write. We do whatever we can to improve. We are patient as a coworker corrects us. We study to increase our skills. A steady diet of reading and contemplation is vital to personal development. It is a matter of self-discipline. We avoid multitasking activities. When communicating with someone else, we are a hundred percent present. We give full attention to the person in front of us (or to the task at hand). We focus on listening and understanding. Read the classic 'Treating Type A Behaviour and Your Heart' by Meyer Friedman. \"Mindfulness\" is paying complete attention to one thing at a time: read 'Full Catastrophe Living' by Jon Kabat-Zinn. When in the office we work hard on Kartoza business. We keep our heads down; we focus, and in turn the company pays well. That's \"the deal\". The work week rarely exceeds forty hours. Complete means \"complete.\" Almost or tomorrow is not \"complete.\" In particular, this is germane to GitHub issues. We strive for a social climate that is serious and quiet yet pleasant, serene, light, and friendly. Kartoza is a nice place to work. As opposed to \"doing the work,\" an \"operations manager's\" job is to create, monitor, and document systems (which consist of people, equipment, procedures, and maintenance schedules). The Managing Director(s) oversee department heads and overall systems. It is the MD's job to direct, coordinate, and monitor the company.","title":"Operating Principles"},{"location":"company/kartoza/operating_principles/#kartozas-thirty-principles","text":"We are innovative. This means we are not set in our ways. We have a diverse toolset and skills and while we retain combinations that work well, we readily change and adapt these and discard those that don't work. Company decisions conform to the Strategic Objective , these Thirty Principles and Working Procedures documents. We are a lean and agile company and follow SAFe principles. We promote open and easy access to information. We provide opportunities for community involvement. We provide opportunities for education and training in FOSS tools and GISc. Our internal systems and client-facing solutions are scalable, resilient and reliable. We are the highest-quality spatial IT company in South Africa and equal to the best globally. We do whatever it takes to ensure the quality of service to our clients, employees and suppliers is impeccable. We draw solid lines, thus providing an exact status of where things stand. Documented procedures are the main defence against grey-area problems. \"Get the job done.\" Can the employee do his or her job, or is there always a complication of one kind or another? This ability to \"get the job done quickly and accurately without excuses or complications\" is the most valuable trait an employee can possess. Employees come first. We employ people who have an innate desire to perform at a hundred percent. We reward them accordingly. The natural outcome is that we serve our clients well. We are not fire killers. We are fire prevention specialists. We don't manage problems; we work on system enhancement and system maintenance to prevent problems from happening in the first place. Problems are gifts that inspire us to action. A problem prompts the act of creating or improving a system or procedure. We don't want setbacks, but when one occurs we think, \"thank you for this wake-up call,\" and take assertive system-improvement action to prevent the setback from happening again. We focus on just [[a few manageable markets|Kartoza Portfolio Offerings]]. Although we watch for new opportunities, in the end we provide \"just a few products and services implemented in superb fashion,\" rather than a complex array of average-quality offerings. We find the simplest solution. Ockham's Law, also called the Law of Economy, states, \"Entities are not to be multiplied beyond necessity . . . the simplest solution is invariably the correct solution.\" The money we save or waste is not Monopoly money! We are careful not to devalue the worth of a Rand (or Dollar or Rupiah or Euro) just because it has to do with the business. We operate the company via documented procedures and systems. \"Any recurring problem can be solved with a system.\" We take the necessary time to create and implement systems and procedures and in the end, it is well worth it. If there is a recurring problem, a written procedure is created to prevent the problem from happening again. On the other hand, we don't bog down the organisation with processes and procedures that target once-in-a-while situations. Sometimes we elect to not create a procedure. \"Just don't do it.\" Eliminate the unnecessary. Many times, elimination of a system, protocol, or potential project is a very good thing. Think simplicity. Automate. Refine to the smallest number of steps or discard altogether. Would a simple \"no\" save time, energy or money? Our documented systems, procedures, and functions are \"off-the-street.\" This means anyone with appropriate training can perform procedures unassisted. The real-world evidence of this is we can hire an individual \"off-the-street\" who has good GIS or programming skills and have him or her doing QGIS or development work within a week. For this result, protocols have to be efficient, simple, and thoroughly documented. Do it NOW. All actions build on \"point-of-sale\" theory. We don't delay an action if it can be done immediately. Just like any major retail outlet, we \"update inventories and databases at the exact time the transaction takes place.\" There is no paperwork floating around the office after a physical transaction. We ask, \"How can we perform the task NOW without creating lingering details that we must clean up later?\" We glean the Kartoza mindset from Stephen Covey's books, including The 7 Habits of Highly Successful People, First Things First, and The 8th Habit. As well, we consider Good to Great by Jim Collins; The E-Myth Revisited by Michael Gerber; Awaken the Giant Within by Anthony Robbins; Maverick by Ricardo Semler; Work the System by Sam Carpenter. We pattern individual organisation upon Franklin-Covey theory. We use organising mechanisms that are always at hand. We prioritise, schedule, and document. The system is always up-to-date and we use it all the time. For Kartoza, these are Github, Google Suite (Mail, Drive, etc.), SyncThing, Sage, OpenProject and others (subject to change as of August 2020) Sequence and priority are critical. We work on the most important tasks first. We spend maximum time on \"non-urgent/important\" tasks via Stephen Covey's time-matrix philosophy. We double-check everything before release. If a penchant for double-checking is not an innate personal habit, then it must be cultivated. Double-checking is a conscious step in every task, performed either by the individual managing the task or someone else. Our environment is spotless: clean and ordered, simple, efficient, functional. No \"rat's nests\", literally or figuratively. Employee training is structured, scheduled, and thorough. Assertive client contact is also structured, scheduled, and thorough. We are deadline-obsessed. If someone in the organisation says they will be finished with a task or project by a certain date and time, then he or she commits to finishing by that deadline (or, if legitimate delays intrude, advise coworkers well in advance that the deadline is impossible to meet). We maintain equipment and keep it a hundred percent functional at all times. If something is not working as it should, fix it now even if it's not necessary to fix it now. It's a matter of good housekeeping and of maintaining good habits. This is just the way we do things. Mastery of the English language is critical. We are aware of how we sound and what we write. We do whatever we can to improve. We are patient as a coworker corrects us. We study to increase our skills. A steady diet of reading and contemplation is vital to personal development. It is a matter of self-discipline. We avoid multitasking activities. When communicating with someone else, we are a hundred percent present. We give full attention to the person in front of us (or to the task at hand). We focus on listening and understanding. Read the classic 'Treating Type A Behaviour and Your Heart' by Meyer Friedman. \"Mindfulness\" is paying complete attention to one thing at a time: read 'Full Catastrophe Living' by Jon Kabat-Zinn. When in the office we work hard on Kartoza business. We keep our heads down; we focus, and in turn the company pays well. That's \"the deal\". The work week rarely exceeds forty hours. Complete means \"complete.\" Almost or tomorrow is not \"complete.\" In particular, this is germane to GitHub issues. We strive for a social climate that is serious and quiet yet pleasant, serene, light, and friendly. Kartoza is a nice place to work. As opposed to \"doing the work,\" an \"operations manager's\" job is to create, monitor, and document systems (which consist of people, equipment, procedures, and maintenance schedules). The Managing Director(s) oversee department heads and overall systems. It is the MD's job to direct, coordinate, and monitor the company.","title":"Kartoza's Thirty Principles"},{"location":"company/kartoza/setting_up_your_computer/","text":"Setting up your PC \u00b6 Hardware \u00b6 Here are the standard minimum guidelines for hardware for Kartoza Staff: Laptops are preferred in general. Many of our staff work in areas with unreliable power supply and so you need to be able to work offline for at least four hours. Admin Staff \u00b6 Admin staff tend to have less demanding activities which is reflected in the hardware: Feature Requirements RAM 8GB Hard Disk 256GB SSD Internal Display 1920 x 1080 or better External Display 1920 x 1080 or better Operating System Ubuntu LTR CPU Mid range e.g. i5 4 core or Athlon equivalent GIS Staff \u00b6 GIS Staff need laptops with good storage capacity for accommodating large GIS datasets, and good processing power to perform time-consuming analysis quickly. Feature Requirements RAM 16GB Hard Disk 1TB SSD Internal Display 1920 x 1080 or better External Display 1920 x 1080 or better Operating System Ubuntu LTR CPU Mid range e.g. i5 4 core or Athlon equivalent Developer Staff & Devops \u00b6 Developer Staff and Devops need laptops with processing power so they can run multiple containers to emulate the deployment environment for their apps. Developer staff tend to have more technical skills and may install their own preference of Operating System if they prefer. Feature Requirements RAM 16GB Hard Disk 500GB SSD Internal Display 1920 x 1080 or better External Display 1920 x 1080 or better Operating System Ubuntu LTR or user preference CPU Mid range e.g. i5 4 core or Athlon equivalent Additional Hardware \u00b6 All staff should in addition be issued with: A USB headset. USB headsets include their own DSP (Digital Sound Processor) and will generally have a better sound quality than an analogue headset. An external disk for backups. This should again be encrypted. The disk should be 4x the size of the hard disk. Use D\u00e9j\u00e0 Dup Backups to run automatic backups on a nightly basis. A kensington lock. This should be used whenever the laptop is left unattended in a public place (i.e. anywhere other than your home). A Yubikey. This will be used to authenticate to Google Apps for Domains (Via Yubikey TOTP), BitWarden, your local PC login (via FIDO2) and other services such as NextCloud. Each staff member should be issued with two of these devices and the second should be stored at home in a safe place in case the first is lost. One of following models are suggested: Base Install Requirements \u00b6 Every staff computer should have the following as a minimum: Encrypted disk. Under Linux use LUKS when you install to encypt at a minimum your home partition. Ideally your whole system should be encrypted since if you run docker, postgres and other similar services, you have exposure to data loss if someone steals your PC. Strong password. The password for your account should not be used for any other system. Yubikey PAM Integration. We recommend as an added precaution to set up the YubiKey PAM module which will require to touch your YubiKey after typing in your system password to autheticate. The process for doing this is described here . Yubkey locks the FIDO2 Pin by default. You should follow these steps to unlock it first before running through the above tutorial. Note they assume you have installed the PPA in the above tutorial above first. Install the YubiKey GUI manager, then use the options as shown below. sudo apt install yubikey-manager-qt ykman-gui Online Accounts \u00b6 You need to have online accounts with the following services: GitHub - then set up your YubiKey as your 2FA here . As a backup 2FA you should use the GitHub mobile app. Note that using SMS for 2FA is not considered secure. Google . Set up your YubiKey as your 2FA here . As a backup 2FA you should use the Google mobile app. Note that using SMS for 2FA is not considered secure. Hetzner . If you are a staff member with permission to access Hetzner, set up your YubiKey as your 2FA here . Note that using SMS for 2FA is not considered secure. ERNext. Our admin team will provision an account for you. NextCloud. Our admin team will provision an account for you. NextCloud . If you are a staff member with permission to access Hetzner, set up your YubiKey as your 2FA here . Note that using SMS for 2FA is not considered secure. Skills \u00b6","title":"Staff Computers"},{"location":"company/kartoza/setting_up_your_computer/#setting-up-your-pc","text":"","title":"Setting up your PC"},{"location":"company/kartoza/setting_up_your_computer/#hardware","text":"Here are the standard minimum guidelines for hardware for Kartoza Staff: Laptops are preferred in general. Many of our staff work in areas with unreliable power supply and so you need to be able to work offline for at least four hours.","title":"Hardware"},{"location":"company/kartoza/setting_up_your_computer/#admin-staff","text":"Admin staff tend to have less demanding activities which is reflected in the hardware: Feature Requirements RAM 8GB Hard Disk 256GB SSD Internal Display 1920 x 1080 or better External Display 1920 x 1080 or better Operating System Ubuntu LTR CPU Mid range e.g. i5 4 core or Athlon equivalent","title":"Admin Staff"},{"location":"company/kartoza/setting_up_your_computer/#gis-staff","text":"GIS Staff need laptops with good storage capacity for accommodating large GIS datasets, and good processing power to perform time-consuming analysis quickly. Feature Requirements RAM 16GB Hard Disk 1TB SSD Internal Display 1920 x 1080 or better External Display 1920 x 1080 or better Operating System Ubuntu LTR CPU Mid range e.g. i5 4 core or Athlon equivalent","title":"GIS Staff"},{"location":"company/kartoza/setting_up_your_computer/#developer-staff--devops","text":"Developer Staff and Devops need laptops with processing power so they can run multiple containers to emulate the deployment environment for their apps. Developer staff tend to have more technical skills and may install their own preference of Operating System if they prefer. Feature Requirements RAM 16GB Hard Disk 500GB SSD Internal Display 1920 x 1080 or better External Display 1920 x 1080 or better Operating System Ubuntu LTR or user preference CPU Mid range e.g. i5 4 core or Athlon equivalent","title":"Developer Staff &amp; Devops"},{"location":"company/kartoza/setting_up_your_computer/#additional-hardware","text":"All staff should in addition be issued with: A USB headset. USB headsets include their own DSP (Digital Sound Processor) and will generally have a better sound quality than an analogue headset. An external disk for backups. This should again be encrypted. The disk should be 4x the size of the hard disk. Use D\u00e9j\u00e0 Dup Backups to run automatic backups on a nightly basis. A kensington lock. This should be used whenever the laptop is left unattended in a public place (i.e. anywhere other than your home). A Yubikey. This will be used to authenticate to Google Apps for Domains (Via Yubikey TOTP), BitWarden, your local PC login (via FIDO2) and other services such as NextCloud. Each staff member should be issued with two of these devices and the second should be stored at home in a safe place in case the first is lost. One of following models are suggested:","title":"Additional Hardware"},{"location":"company/kartoza/setting_up_your_computer/#base-install-requirements","text":"Every staff computer should have the following as a minimum: Encrypted disk. Under Linux use LUKS when you install to encypt at a minimum your home partition. Ideally your whole system should be encrypted since if you run docker, postgres and other similar services, you have exposure to data loss if someone steals your PC. Strong password. The password for your account should not be used for any other system. Yubikey PAM Integration. We recommend as an added precaution to set up the YubiKey PAM module which will require to touch your YubiKey after typing in your system password to autheticate. The process for doing this is described here . Yubkey locks the FIDO2 Pin by default. You should follow these steps to unlock it first before running through the above tutorial. Note they assume you have installed the PPA in the above tutorial above first. Install the YubiKey GUI manager, then use the options as shown below. sudo apt install yubikey-manager-qt ykman-gui","title":"Base Install Requirements"},{"location":"company/kartoza/setting_up_your_computer/#online-accounts","text":"You need to have online accounts with the following services: GitHub - then set up your YubiKey as your 2FA here . As a backup 2FA you should use the GitHub mobile app. Note that using SMS for 2FA is not considered secure. Google . Set up your YubiKey as your 2FA here . As a backup 2FA you should use the Google mobile app. Note that using SMS for 2FA is not considered secure. Hetzner . If you are a staff member with permission to access Hetzner, set up your YubiKey as your 2FA here . Note that using SMS for 2FA is not considered secure. ERNext. Our admin team will provision an account for you. NextCloud. Our admin team will provision an account for you. NextCloud . If you are a staff member with permission to access Hetzner, set up your YubiKey as your 2FA here . Note that using SMS for 2FA is not considered secure.","title":"Online Accounts"},{"location":"company/kartoza/setting_up_your_computer/#skills","text":"","title":"Skills"},{"location":"company/kartoza/strategic_objective/","text":"Kartoza's Strategic Objective \u00b6 The Kartoza Strategic Objective is the basis for all corporate and individual decision making. Statistically we are the largest FOSS geospatial service provider in South Africa and in the top ten globally. We show up on the first page of google.com and google.co.za searches for these keywords: 'open source GIS'; 'FOSS GIS training'; 'FOSS GIS support'; 'geospatial web development'; 'QGIS development' We aim to grow Kartoza revenue by 15% year on year. We aim to grow our staff complement on a sustainable basis till we reach around 25. We understand that every result is preceded by a 1-2-3-4 step process. It is within these processes that we spend our time, as we relentlessly \"work\" the systems of the business to perfection. Our guiding documents are this Strategic Objective, Our Kartoza Operating Principles , and our collection of Working Procedures . Kartoza's primary offerings are geospatial products and services using Free and Open Source Software. These facilitate spatial decision making and provide tools for economic empowerment. Through intense commitment to our employees, we will contribute to the success of our clients. The consequence of having loyal, smart, hard-working, long-term, and well-compensated staff is superb quality service to customers. Our business is complex, with many human, mechanical and computer systems in simultaneous motion. Success depends on refined communication and organisational processes, dedicated staff, documented procedures, first-class office space and equipment, rigorous quality assurance with continuous measurement, assertive innovation, intense planned maintenance and system improvement, aggressive and measured marketing, and relentless attention to detail in every nook and cranny. Our competitive advantages include an established track record, our ability to solve complex problems with great design, products designed around the unique needs of the customer, thoughtful customer service that is immediate and consistent, the latest high-tech equipment and personal and corporate integrity. We use extraordinarily efficient business systems. We constantly refine and improve all internal systems and mechanisms. To grow, we follow a two-pronged strategy of: Pursuing substantial consulting, development and implementation projects in our target markets Building products and services that generate passive income, juxtaposed with assertive marketing efforts. Although we tightly direct Kartoza's operation through guiding documentation, we will modify that documentation immediately if an enhancement can be made: \"Our operational framework is rigid, but that framework can be modified instantly.\" We segment responsibilities into specialised \"expert compartments\" with appropriate cross-training among departments. We have backup personnel for all positions. Kartoza is globally active and locally relevant. Our primary vertical markets include: Agriculture Disaster preparedness, response and management Land information management Education Humanitarian support SDI support Monitoring and observation Biodiversity and conservation support (These are fleshed out in [ Kartoza-Portfolio-Offerings ) Kartoza aims to model itself on the concept of a B-Corporation , in the sense that through the work we do and the people we employ, we aim to be socially and environmentally responsible.","title":"Strategic Objective"},{"location":"company/kartoza/strategic_objective/#kartozas-strategic-objective","text":"The Kartoza Strategic Objective is the basis for all corporate and individual decision making. Statistically we are the largest FOSS geospatial service provider in South Africa and in the top ten globally. We show up on the first page of google.com and google.co.za searches for these keywords: 'open source GIS'; 'FOSS GIS training'; 'FOSS GIS support'; 'geospatial web development'; 'QGIS development' We aim to grow Kartoza revenue by 15% year on year. We aim to grow our staff complement on a sustainable basis till we reach around 25. We understand that every result is preceded by a 1-2-3-4 step process. It is within these processes that we spend our time, as we relentlessly \"work\" the systems of the business to perfection. Our guiding documents are this Strategic Objective, Our Kartoza Operating Principles , and our collection of Working Procedures . Kartoza's primary offerings are geospatial products and services using Free and Open Source Software. These facilitate spatial decision making and provide tools for economic empowerment. Through intense commitment to our employees, we will contribute to the success of our clients. The consequence of having loyal, smart, hard-working, long-term, and well-compensated staff is superb quality service to customers. Our business is complex, with many human, mechanical and computer systems in simultaneous motion. Success depends on refined communication and organisational processes, dedicated staff, documented procedures, first-class office space and equipment, rigorous quality assurance with continuous measurement, assertive innovation, intense planned maintenance and system improvement, aggressive and measured marketing, and relentless attention to detail in every nook and cranny. Our competitive advantages include an established track record, our ability to solve complex problems with great design, products designed around the unique needs of the customer, thoughtful customer service that is immediate and consistent, the latest high-tech equipment and personal and corporate integrity. We use extraordinarily efficient business systems. We constantly refine and improve all internal systems and mechanisms. To grow, we follow a two-pronged strategy of: Pursuing substantial consulting, development and implementation projects in our target markets Building products and services that generate passive income, juxtaposed with assertive marketing efforts. Although we tightly direct Kartoza's operation through guiding documentation, we will modify that documentation immediately if an enhancement can be made: \"Our operational framework is rigid, but that framework can be modified instantly.\" We segment responsibilities into specialised \"expert compartments\" with appropriate cross-training among departments. We have backup personnel for all positions. Kartoza is globally active and locally relevant. Our primary vertical markets include: Agriculture Disaster preparedness, response and management Land information management Education Humanitarian support SDI support Monitoring and observation Biodiversity and conservation support (These are fleshed out in [ Kartoza-Portfolio-Offerings ) Kartoza aims to model itself on the concept of a B-Corporation , in the sense that through the work we do and the people we employ, we aim to be socially and environmentally responsible.","title":"Kartoza's Strategic Objective"},{"location":"development/","text":"Development \u00b6 Note that all users, regardless of role, should understand and review the security section. Kartoza is a consulting and development firm. In many instances, projects require developers to leverage existing tools and codebases, and to work with other organisations in a way that is consistent in their own conventions. This documentation seeks to outline processes and practices so that internal project development and practices within the team remain consistent. Where it is noted that beneficial conventions listed here are not implemented in client projects, recommendations may be made that clients adopt such standards. For the most part, however, it is less a concern of how a particular outcome is achieved, but rather that the result is consistent with the appropriate conventions. Conventions Technologies Environments","title":"Development"},{"location":"development/#development","text":"Note that all users, regardless of role, should understand and review the security section. Kartoza is a consulting and development firm. In many instances, projects require developers to leverage existing tools and codebases, and to work with other organisations in a way that is consistent in their own conventions. This documentation seeks to outline processes and practices so that internal project development and practices within the team remain consistent. Where it is noted that beneficial conventions listed here are not implemented in client projects, recommendations may be made that clients adopt such standards. For the most part, however, it is less a concern of how a particular outcome is achieved, but rather that the result is consistent with the appropriate conventions. Conventions Technologies Environments","title":"Development"},{"location":"development/conventions/","text":"Conventions \u00b6 https://kartoza.com/en/coding-standards/ IDEs Processes Git Project Conventions \u00b6 SDLC, agile, scrumboards: i.e. project processes Language Conventions \u00b6 A foolish consistency... Python \u00b6 python specific content JavaScript \u00b6 js specific content C++ \u00b6 c++ specific content","title":"Conventions"},{"location":"development/conventions/#conventions","text":"https://kartoza.com/en/coding-standards/ IDEs Processes Git","title":"Conventions"},{"location":"development/conventions/#project-conventions","text":"SDLC, agile, scrumboards: i.e. project processes","title":"Project Conventions"},{"location":"development/conventions/#language-conventions","text":"A foolish consistency...","title":"Language Conventions"},{"location":"development/conventions/#python","text":"python specific content","title":"Python"},{"location":"development/conventions/#javascript","text":"js specific content","title":"JavaScript"},{"location":"development/conventions/#c","text":"c++ specific content","title":"C++"},{"location":"development/conventions/dev_processes/","text":"Development Processes \u00b6 Development processes https://kartoza.com/en/coding-standards/ https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html","title":"Development Processes"},{"location":"development/conventions/dev_processes/#development-processes","text":"Development processes https://kartoza.com/en/coding-standards/ https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html","title":"Development Processes"},{"location":"development/conventions/git/","text":"Git \u00b6 Tell everyone to use GitLens. It's amazing Outline other standard processes and tools (precommits, hooks, workflows, gitflows etc)","title":"Git"},{"location":"development/conventions/git/#git","text":"Tell everyone to use GitLens. It's amazing Outline other standard processes and tools (precommits, hooks, workflows, gitflows etc)","title":"Git"},{"location":"development/conventions/ides/","text":"IDEs \u00b6 This section covers Integrated Development Environments. Whilst it is not required that all users leverage the same IDE, it is beneficial to have a consistent environment across the team and ensure all team members have access to the appropriate tools. VSCode (almost anything) Pycharm QTCreator Configuration \u00b6 Recommended and required configurations should be listed here General opinions can be handed off to Environment Links VSCode \u00b6 GitLens (recommended): Really great UX and insights into git GitMoji (recommended): Don't forget to use emoji in your commit messages","title":"IDEs"},{"location":"development/conventions/ides/#ides","text":"This section covers Integrated Development Environments. Whilst it is not required that all users leverage the same IDE, it is beneficial to have a consistent environment across the team and ensure all team members have access to the appropriate tools. VSCode (almost anything) Pycharm QTCreator","title":"IDEs"},{"location":"development/conventions/ides/#configuration","text":"Recommended and required configurations should be listed here General opinions can be handed off to Environment Links","title":"Configuration"},{"location":"development/conventions/ides/#vscode","text":"GitLens (recommended): Really great UX and insights into git GitMoji (recommended): Don't forget to use emoji in your commit messages","title":"VSCode"},{"location":"development/conventions/project_processes/","text":"Project Processes \u00b6 Make GitHub projects (in the project repo or kartoza organisation?) Keep those projects up to date graph LR A[Check for existing task]-->B[Update task state]; B-->C[Perform work on task]; C-->D[Commit changes]; D-->B;","title":"Project Processes"},{"location":"development/conventions/project_processes/#project-processes","text":"Make GitHub projects (in the project repo or kartoza organisation?) Keep those projects up to date graph LR A[Check for existing task]-->B[Update task state]; B-->C[Perform work on task]; C-->D[Commit changes]; D-->B;","title":"Project Processes"},{"location":"development/environments/","text":"Environments \u00b6 Development environments configurations and conventions (conda/ venv/ poetry/ git codespaces/ docker workspaces etc) Links and external resources","title":"Environments"},{"location":"development/environments/#environments","text":"Development environments configurations and conventions (conda/ venv/ poetry/ git codespaces/ docker workspaces etc) Links and external resources","title":"Environments"},{"location":"development/environments/links/","text":"Development Resources \u00b6 External resources, links, and recommendations fo development environment configuration. VSCode \u00b6 see links SQL \u00b6 Use postgresql for everything. Dbeaver and Pgadmin are good tools. https://www.beekeeperstudio.io/","title":"Development Resources"},{"location":"development/environments/links/#development-resources","text":"External resources, links, and recommendations fo development environment configuration.","title":"Development Resources"},{"location":"development/environments/links/#vscode","text":"see links","title":"VSCode"},{"location":"development/environments/links/#sql","text":"Use postgresql for everything. Dbeaver and Pgadmin are good tools. https://www.beekeeperstudio.io/","title":"SQL"},{"location":"development/environments/vscode/extension_install/","text":"Bulk Extension Installation \u00b6 If you want to install VSCode extensions suggested by Rudolf, you can follow these steps. Open this file . Copy the contents. Open VSCode. Open a new terminal Paste the file content in the terminal. This should install all the extensions (can take a while). This setup is a bit general case, with a heavy focus on python and django naturally.","title":"Bulk Extension Installation"},{"location":"development/environments/vscode/extension_install/#bulk-extension-installation","text":"If you want to install VSCode extensions suggested by Rudolf, you can follow these steps. Open this file . Copy the contents. Open VSCode. Open a new terminal Paste the file content in the terminal. This should install all the extensions (can take a while). This setup is a bit general case, with a heavy focus on python and django naturally.","title":"Bulk Extension Installation"},{"location":"development/environments/vscode/links/","text":"VSCode Resources \u00b6 External resources, links, and recommendations fo VSCode configuration. Suggestions from Rudolph, 2022/04 Lightweight postman alternative inside vsc https://marketplace.visualstudio.com/items?itemName=humao.rest-client Manage all your unit tests in a neat organised side bar in vsc - check docs for install guide. Also works with basically all test frameworks! https://marketplace.visualstudio.com/items?itemName=hbenl.vscode-test-explorer https://marketplace.visualstudio.com/items?itemName=ms-vscode.test-adapter-converter https://marketplace.visualstudio.com/items?itemName=LittleFoxTeam.vscode-python-test-adapter Track how much time you spend on all your projects. also tracks lines of code added/deleted/etc https://marketplace.visualstudio.com/items?itemName=iceworks-team.iceworks-time-master Docker management https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers Django snippets - this extension is a bit hidden away for some reason. This is really awesome for django dev specific snippets for models, forms, views etc. really useful! https://marketplace.visualstudio.com/items?itemName=thebarkman.vscode-djaneiro Python Docstrings - but I'm sure there are better extensions https://marketplace.visualstudio.com/items?itemName=njpwerner.autodocstring I have a few other quality of life extensions: https://marketplace.visualstudio.com/items?itemName=vscode-icons-team.vscode-icons - essential https://marketplace.visualstudio.com/items?itemName=adam-watters.vscode-color-pick - front end devs looking for colour codes https://marketplace.visualstudio.com/items?itemName=johnpapa.vscode-peacock - livens up vsc theme with a splash of colour https://marketplace.visualstudio.com/items?itemName=formulahendry.auto-rename-tag - html auto rename the closing tag https://marketplace.visualstudio.com/items?itemName=formulahendry.auto-close-tag - creates closing tag (helpful when using html in not html files like Vue, but might be unnecessary lol) Honorary mentions: https://marketplace.visualstudio.com/items?itemName=donjayamanne.python-extension-pack https://marketplace.visualstudio.com/items?itemName=alefragnani.project-manager https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode https://marketplace.visualstudio.com/items?itemName=donjayamanne.git-extension-pack https://marketplace.visualstudio.com/items?itemName=uctakeoff.vscode-counter -All the intellisense extensions for all the languages :) A lot of these extensions have alternatives as well so it's recommended to play around with a few of them.","title":"VSCode Resources"},{"location":"development/environments/vscode/links/#vscode-resources","text":"External resources, links, and recommendations fo VSCode configuration. Suggestions from Rudolph, 2022/04 Lightweight postman alternative inside vsc https://marketplace.visualstudio.com/items?itemName=humao.rest-client Manage all your unit tests in a neat organised side bar in vsc - check docs for install guide. Also works with basically all test frameworks! https://marketplace.visualstudio.com/items?itemName=hbenl.vscode-test-explorer https://marketplace.visualstudio.com/items?itemName=ms-vscode.test-adapter-converter https://marketplace.visualstudio.com/items?itemName=LittleFoxTeam.vscode-python-test-adapter Track how much time you spend on all your projects. also tracks lines of code added/deleted/etc https://marketplace.visualstudio.com/items?itemName=iceworks-team.iceworks-time-master Docker management https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers Django snippets - this extension is a bit hidden away for some reason. This is really awesome for django dev specific snippets for models, forms, views etc. really useful! https://marketplace.visualstudio.com/items?itemName=thebarkman.vscode-djaneiro Python Docstrings - but I'm sure there are better extensions https://marketplace.visualstudio.com/items?itemName=njpwerner.autodocstring I have a few other quality of life extensions: https://marketplace.visualstudio.com/items?itemName=vscode-icons-team.vscode-icons - essential https://marketplace.visualstudio.com/items?itemName=adam-watters.vscode-color-pick - front end devs looking for colour codes https://marketplace.visualstudio.com/items?itemName=johnpapa.vscode-peacock - livens up vsc theme with a splash of colour https://marketplace.visualstudio.com/items?itemName=formulahendry.auto-rename-tag - html auto rename the closing tag https://marketplace.visualstudio.com/items?itemName=formulahendry.auto-close-tag - creates closing tag (helpful when using html in not html files like Vue, but might be unnecessary lol) Honorary mentions: https://marketplace.visualstudio.com/items?itemName=donjayamanne.python-extension-pack https://marketplace.visualstudio.com/items?itemName=alefragnani.project-manager https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode https://marketplace.visualstudio.com/items?itemName=donjayamanne.git-extension-pack https://marketplace.visualstudio.com/items?itemName=uctakeoff.vscode-counter -All the intellisense extensions for all the languages :) A lot of these extensions have alternatives as well so it's recommended to play around with a few of them.","title":"VSCode Resources"},{"location":"development/technologies/","text":"Technologies \u00b6 It makes sense to attempt some level of standardisation across development practices, including technologies and frameworks in use, so that the barrier for entry to projects is lowered and it becomes simple to maintain consistent practices across the organisation. Languages Frameworks Evaluating \u00b6 It may be helpful to include some \"smell tests\" for evaluating good projects or technologies","title":"Languages"},{"location":"development/technologies/#technologies","text":"It makes sense to attempt some level of standardisation across development practices, including technologies and frameworks in use, so that the barrier for entry to projects is lowered and it becomes simple to maintain consistent practices across the organisation. Languages Frameworks","title":"Technologies"},{"location":"development/technologies/#evaluating","text":"It may be helpful to include some \"smell tests\" for evaluating good projects or technologies","title":"Evaluating"},{"location":"development/technologies/frameworks/","text":"Frameworks \u00b6 Standardise on the frameworks used to encourage collaboration and efficiency. Cross platform \u00b6 QT (multiple) React native (js) Flutter (dart) Quasar (js) Beeware (python) Kivy (python) Desktop \u00b6 See the cross platform section. tauri (js/ rust): Uses a rust backend and javascript frontend as a more performant alternative to electron, which bundles chromium into every build. Mobile \u00b6 If you're not going native, use the cross platform frameworks please. Web \u00b6 Django (python): Default to django. It's batteries included. Flask (python): Light weight python server FastApi (python): It's shiny, but pretty great. If you're a fan of starlette and async, and you only want a REST API, FastApi is where you might want to head. 90% of the time, use django+drf, or extend flask (more of the team can help you out there too). If you have to ask if you should use it, you probably shouldn't. Express (js): Serverside js. NextJS (js): Serverside react. Rails (ruby): If you are using or extending something in ruby (not recommended) tauri : Uses a rust backend and javascript frontend as a more performant alternative to electron, which bundles chromium into every build. Docs \u00b6 Use Material Mkdocs Jamstack \u00b6 Default to Hugo. GIS \u00b6 OpenLayers, Leaflet, and CesiumJS. Turf.js, MapLibre. GeoDjango. pg_featureserv/ pg_tilserv. UI \u00b6 Ensuring that consistent UI component libraries are used improves quality, efficiency, and consistency across applications and the overall UX. CSS frameworks \u00b6 Bootstrap, bulma, tailwind Component libraries \u00b6 Nobody will stop you from starting an app in kotlin, but it's unlikely to get the momentum or collaboration that is desired within the organisation.","title":"Frameworks"},{"location":"development/technologies/frameworks/#frameworks","text":"Standardise on the frameworks used to encourage collaboration and efficiency.","title":"Frameworks"},{"location":"development/technologies/frameworks/#cross-platform","text":"QT (multiple) React native (js) Flutter (dart) Quasar (js) Beeware (python) Kivy (python)","title":"Cross platform"},{"location":"development/technologies/frameworks/#desktop","text":"See the cross platform section. tauri (js/ rust): Uses a rust backend and javascript frontend as a more performant alternative to electron, which bundles chromium into every build.","title":"Desktop"},{"location":"development/technologies/frameworks/#mobile","text":"If you're not going native, use the cross platform frameworks please.","title":"Mobile"},{"location":"development/technologies/frameworks/#web","text":"Django (python): Default to django. It's batteries included. Flask (python): Light weight python server FastApi (python): It's shiny, but pretty great. If you're a fan of starlette and async, and you only want a REST API, FastApi is where you might want to head. 90% of the time, use django+drf, or extend flask (more of the team can help you out there too). If you have to ask if you should use it, you probably shouldn't. Express (js): Serverside js. NextJS (js): Serverside react. Rails (ruby): If you are using or extending something in ruby (not recommended) tauri : Uses a rust backend and javascript frontend as a more performant alternative to electron, which bundles chromium into every build.","title":"Web"},{"location":"development/technologies/frameworks/#docs","text":"Use Material Mkdocs","title":"Docs"},{"location":"development/technologies/frameworks/#jamstack","text":"Default to Hugo.","title":"Jamstack"},{"location":"development/technologies/frameworks/#gis","text":"OpenLayers, Leaflet, and CesiumJS. Turf.js, MapLibre. GeoDjango. pg_featureserv/ pg_tilserv.","title":"GIS"},{"location":"development/technologies/frameworks/#ui","text":"Ensuring that consistent UI component libraries are used improves quality, efficiency, and consistency across applications and the overall UX.","title":"UI"},{"location":"development/technologies/frameworks/#css-frameworks","text":"Bootstrap, bulma, tailwind","title":"CSS frameworks"},{"location":"development/technologies/frameworks/#component-libraries","text":"Nobody will stop you from starting an app in kotlin, but it's unlikely to get the momentum or collaboration that is desired within the organisation.","title":"Component libraries"},{"location":"development/technologies/languages/","text":"Languages \u00b6 Focus is on python, javascript, and C++, but anything goes really. Note that python is the preferred language for tool and application implementation for a number of reasons, including having consistent tooling and ensuring that everyone on the team is able to collaborate . By remaining consistent and lowering the Javascript cannot be escaped on the modern web, and so is a requirement by default. In instances where is makes sense, using serverside javascript is certainly supported, but python is still the preferred approach. C++ is used for QGIS development and the focus for conventions will be on using C++ with QT. There are no strict rules applied to technology, so everybody is free to use whatever works, and a key ability in open source ecosystems is to remain adaptable and be capable of leveraging the existing tools that are the best available. Stand on the shoulders of giants where you can. Because these are not considered core competencies, there aren't really any expectations, requirements, or recommendations that apply to other ecosystems. How users choose to code in rust, go, ruby, or c is entirely up to them. But there are caveats. Boring solutions often work best. The newest shiny can be fun but it's rarely a good idea to dive into early adoption. Team work is important, and it's hard to work as a team when you're using esoteric tools. When in doubt, have a look at a chart of Diffusion of innovations and try assess if the current position is at the end of the early adopter and start of the early majority group. This includes the development of mobile, cross platform, or native apps. Whilst universal support for PWAs lingers, it is still a way off from being the de facto standard for the development industry. In the meantime, stick to using tools that the rest of the team can get up to speed with quickly or have experience with, such as QT, python, or javascript. Nobody will stop you from starting an app in kotlin, but it's unlikely to get the momentum or collaboration that is desired within the organisation.","title":"Languages"},{"location":"development/technologies/languages/#languages","text":"Focus is on python, javascript, and C++, but anything goes really. Note that python is the preferred language for tool and application implementation for a number of reasons, including having consistent tooling and ensuring that everyone on the team is able to collaborate . By remaining consistent and lowering the Javascript cannot be escaped on the modern web, and so is a requirement by default. In instances where is makes sense, using serverside javascript is certainly supported, but python is still the preferred approach. C++ is used for QGIS development and the focus for conventions will be on using C++ with QT. There are no strict rules applied to technology, so everybody is free to use whatever works, and a key ability in open source ecosystems is to remain adaptable and be capable of leveraging the existing tools that are the best available. Stand on the shoulders of giants where you can. Because these are not considered core competencies, there aren't really any expectations, requirements, or recommendations that apply to other ecosystems. How users choose to code in rust, go, ruby, or c is entirely up to them. But there are caveats. Boring solutions often work best. The newest shiny can be fun but it's rarely a good idea to dive into early adoption. Team work is important, and it's hard to work as a team when you're using esoteric tools. When in doubt, have a look at a chart of Diffusion of innovations and try assess if the current position is at the end of the early adopter and start of the early majority group. This includes the development of mobile, cross platform, or native apps. Whilst universal support for PWAs lingers, it is still a way off from being the de facto standard for the development industry. In the meantime, stick to using tools that the rest of the team can get up to speed with quickly or have experience with, such as QT, python, or javascript. Nobody will stop you from starting an app in kotlin, but it's unlikely to get the momentum or collaboration that is desired within the organisation.","title":"Languages"},{"location":"devops/","text":"DevOps \u00b6 Resources, information, and processes related to DevOps and system administration. Note that all users, regardless of role, should understand and review the security section. Note that this is not limited to DevOps team members and may include conventions and configuration for the management of workstations, servers, and other systems, which is relevant to multiple roles. Security Procedures Infrastructure","title":"DevOps"},{"location":"devops/#devops","text":"Resources, information, and processes related to DevOps and system administration. Note that all users, regardless of role, should understand and review the security section. Note that this is not limited to DevOps team members and may include conventions and configuration for the management of workstations, servers, and other systems, which is relevant to multiple roles. Security Procedures Infrastructure","title":"DevOps"},{"location":"devops/applications/standard-applications/","text":"Standard Deployment Applications \u00b6 Geoserver Filebrowser pg-backups Postgres","title":"Standard Deployment Applications"},{"location":"devops/applications/standard-applications/#standard-deployment-applications","text":"Geoserver Filebrowser pg-backups Postgres","title":"Standard Deployment Applications"},{"location":"devops/infrastructure/","text":"Infrastructure \u00b6 Development Infrastructure Personal Infrastructure Containers Kubernetes Rancher Rancher Desktop Development Staging Production CI/CD Rancher Topics \u00b6 Using Rancher, K3S, and Longhorn for single node Kubernetes deployment","title":"Infrastructure"},{"location":"devops/infrastructure/#infrastructure","text":"Development Infrastructure Personal Infrastructure Containers Kubernetes Rancher Rancher Desktop Development Staging Production CI/CD","title":"Infrastructure"},{"location":"devops/infrastructure/#rancher-topics","text":"Using Rancher, K3S, and Longhorn for single node Kubernetes deployment","title":"Rancher Topics"},{"location":"devops/infrastructure/personal_infrastructure/","text":"Personal Kubernetes Infrastructure \u00b6 Initial Setup \u00b6 This are initial notes from Tim on setting up a personal docker, rancher desktop and rancher server testbed environment. I started by setting up rancher desktop on my Fedora based linux laptop. I used the appimage (despite a concerning looking warning that firefox gives about the image when downloading it.) Here is the installation guide . Note: After upgrading to fedora 36 rancher desktop no longer started until I applied the following fix: https://github.com/rancher-sandbox/rancher-desktop/issues/2139#issuecomment-1114933138 Once installed I performed the following commands to do a quick start setup of nginx running in the k8 cluster. kubectl get nodes NAME STATUS ROLES AGE VERSION lima-rancher-desktop Ready control-plane,master 80m v1.22.7+k3s1 kubectl create deployment nginx --image = nginx deployment.apps/nginx created kubectl get pods NAME READY STATUS RESTARTS AGE nginx-6799fc88d8-7k4kd 0/1 ContainerCreating 0 10s kubectl describe nginx-6799fc88d8-7k4kd error: the server doesn't have a resource type \"nginx-6799fc88d8-7k4kd\" kubectl describe pod nginx-6799fc88d8-7k4kd Name: nginx-6799fc88d8-7k4kd Namespace: default Priority: 0 Node: lima-rancher-desktop/192.168.5.15 Start Time: Sat, 23 Apr 2022 22:57:06 +0100 Labels: app=nginx pod-template-hash=6799fc88d8 Annotations: none Status: Running IP: 10.42.0.9 IPs: IP: 10.42.0.9 Controlled By: ReplicaSet/nginx-6799fc88d8 Containers: nginx: > Container ID: containerd://f85e833716a254f9e981ebf6c0f432edab366aacdfa74cc46b84904e6afc8760 Image: nginx > Image ID: docker.io/library/nginx@sha256:859ab6768a6f26a79bc42b231664111317d095a4f04e4b6fe79ce37b3d199097 Port: none Host Port: none State: Running Started: Sat, 23 Apr 2022 22:57:23 +0100 Ready: True Restart Count: 0 Environment: none Mounts: > /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-hl4hc (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-hl4hc: > Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: nil DownwardAPI: true QoS Class: BestEffort Node-Selectors: none Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s > node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 33s default-scheduler Successfully assigned default/nginx-6799fc88d8-7k4kd to lima-rancher-desktop Normal Pulling 33s kubelet Pulling image \"nginx\" Normal Pulled 17s kubelet Successfully pulled image \"nginx\" in 16.398944871s Normal Created 17s kubelet Created container nginx Normal Started 16s kubelet Started container nginx kubectl get pods NAME READY STATUS RESTARTS AGE nginx-6799fc88d8-7k4kd 1/1 Running 0 44s kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-6799fc88d8-7k4kd 1/1 Running 0 57s 10.42.0.9 lima-rancher-desktop none none kubectl exec -it nginx-6799fc88d8-7k4kd /bin/sh kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future > > version. Use kubectl exec [POD] -- [COMMAND] instead. curl 10 .42.0.9 Welcome to nginx! html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } Welcome to nginx! If you see this page, the nginx web server is successfully installed and working. Further configuration is required. For online documentation and support please refer to nginx.org Commercial support is available at nginx.com Thank you for using nginx. exit \u00b6 kubectl get pods `` > NAME READY STATUS RESTARTS AGE > nginx-6799fc88d8-7k4kd 1 /1 Running 0 2m45s These steps are verbatim from [ this youtube video ]( https://www.youtube.com/watch?v = LwE8IA3glE4 ) . From this initial run through we can assume these basic concepts: ! [ K8 Concepts ]( img/k8-concepts.png ) ## Deploying Rancher on Rancher Desktop I remember that Dominic explained about namespaces in his initial walk through so let me try to create a new namespace. ``` bash kubectl create namespace tim While trying to figure out how to list my namespaces, I found this nice k8 cheatsheet . The above cheatsheet didnt actually contain the tip I needed but a bit of googling came up with this: kubectl get namespaces --show-labels NAME STATUS AGE LABELS default Active 141m kubernetes.io/metadata.name=default kube-system Active 141m kubernetes.io/metadata.name=kube-system kube-public Active 141m kubernetes.io/metadata.name=kube-public kube-node-lease Active 141m kubernetes.io/metadata.name=kube-node-lease tim Active 3m34s kubernetes.io/metadata.name=tim You can see my tim namespace listed as the last entry there. So based on doing that, I think I can update my concept diagram to look like this: kubectl apiVersion: v1 kind: Pod metadata: name: nginxpod namespace: tim labels: name: nginxpod spec: containers: name: web image: nginx I saved the above as nginx.yml and was able to run it like this: kubectl apply -f nginx.yml Then I could check in the tim namespace to see if it was running: kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system local-path-provisioner-84bb864455-dsv47 1/1 Running 0 150m kube-system helm-install-traefik-crd--1-xrhvf 0/1 Completed 0 150m kube-system svclb-traefik-p9zwj 2/2 Running 0 150m kube-system helm-install-traefik--1-m2r2x 0/1 Completed 1 150m kube-system coredns-96cc4f57d-5bzj8 1/1 Running 0 150m kube-system traefik-56c4b88c4b-mpwfm 1/1 Running 0 150m kube-system metrics-server-ff9dbcb6c-6gzt5 1/1 Running 0 150m default nginx-6799fc88d8-7k4kd 1/1 Running 0 69m tim nginxpod 1/1 Running 0 14s We can see my nginx pod in my namespace as the last entry. Installing Rancher on Rancher Desktop \u00b6 I went here for instructions. helm repo add rancher-latest https://releases.rancher.com/server-charts/latest kubectl create namespace cattle-system helm install rancher rancher-latest/rancher --namespace cattle-system --set hostname = crest --set replicas = 1 --set ingress.tls.source = secret A little note here: the above tutorial provides different pathways to get a certificate. I am using ingress.tls.source=secret because I am just running on my local sytstem. In production you probably want to use a different option. Also I reduced replicas to 1 since I only have 1 pod in my local test environment. After running, I got a nice message saying rancher is setting itself up: NAME: rancher LAST DEPLOYED: Sun Apr 24 11:25:45 2022 NAMESPACE: cattle-system STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: Rancher Server has been installed. NOTE: Rancher may take several minutes to fully initialize. Please standby while Certificates are being issued, Containers are started and the Ingress rule comes up. Check out our docs at https://rancher.com/docs/ If you provided your own bootstrap password during installation, browse to https://crest to get started. If this is the first time you installed Rancher, get started by running this command and clicking the URL it generates: echo https://crest/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}') To get just the bootstrap password on its own, run: kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}{{ \"\\n\" }}' Happy Containering! ``` Let's use our experience from the simple nginx deployment to see what is running on the system now: kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system helm-install-traefik-crd--1-xrhvf 0/1 Completed 0 13h kube-system helm-install-traefik--1-m2r2x 0/1 Completed 1 13h kube-system svclb-traefik-p9zwj 2/2 Running 2 (10m ago) 13h kube-system local-path-provisioner-84bb864455-dsv47 1/1 Running 1 (10m ago) 13h kube-system coredns-96cc4f57d-5bzj8 1/1 Running 1 (10m ago) 13h tim nginxpod 1/1 Running 1 (10m ago) 11h default nginx-6799fc88d8-7k4kd 1/1 Running 1 (10m ago) 12h kube-system traefik-56c4b88c4b-mpwfm 1/1 Running 1 (10m ago) 13h kube-system metrics-server-ff9dbcb6c-6gzt5 1/1 Running 1 (10m ago) 13h cattle-system rancher-6448c4dcdf-8wpsk 1/1 Running 0 3m37s cattle-fleet-system gitjob-cc9948fd7-jxgg5 1/1 Running 0 44s cattle-fleet-system fleet-controller-5746685958-f4rx5 1/1 Running 0 44s cattle-system helm-operation-zfbfq 0/2 Completed 0 68s cattle-system helm-operation-5sg9s 0/2 Completed 0 16s cattle-system helm-operation-n6ggh 2/2 Running 0 10s cattle-fleet-local-system fleet-agent-6c6c8c45f8-vtbnm 0/1 ContainerCreating 0 7s cattle-system rancher-webhook-6958cfcddf-z9rxr 0/1 ContainerCreating 0 5s We can see various jobs are still spinning up in the cattle-system. Next I went on a little detour on creating a self signed certificate that I can install in my rancher instance. openssl req -new -newkey rsa:4096 -x509 -sha256 -days 365 \\ -nodes -out tls.crt -keyout tls.key Note: I believe it is required to name the key tls.* so as to match the secret name. Which outputs this: Generating a RSA private key writing new private key to 'tls.key' You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. Country Name (2 letter code) [XX]:pt State or Province Name (full name) []: Locality Name (eg, city) [Default City]: Organization Name (eg, company) [Default Company Ltd]: Organizational Unit Name (eg, section) []: Common Name (eg, your name or your server's hostname) []: Email Address []:tim@kartoza.com Then we have two certs in our directory: ls tls.crt tls.key nginx.yml Then on this rancher page , I followed these notes to install my cert: kubectl -n cattle-system create secret tls tls-rancher-ingress \\ --cert = tls.crt \\ --key = tls.key secret/tls-rancher-ingress created Ok then back to the main thread of the rancher installation tutorial I continued: kubectl -n cattle-system rollout status deploy/rancher Which returns this: deployment \"rancher\" successfully rolled out Testing it out \u00b6 The instructions say to open the host in your browser (in my case I used my local hostname of crest), but nothing opened. I took a look in rancher desktop and played with the port forwarding. The default install looked like this: So I went ahead and tried to forward that rancher port: Then tried to open https://localhost:37443/ Which gave me an error: The thing seems to be that you need to rather forward this port: Then I was able ot open the site (different port number now) an set up my credentials following the hints provided. Note : Since I am using a self signed cert I had to do the normal firefox security warning process to proceed to the site. I did however still have some errors now showing in rancher: Deploying a small application from a helm chart \u00b6 I know helm charts are like the package managers of kubernetes, but I am not familiar with them, so I went to make a small test with the filebrowser.org (awesome app btw). I found these instructions and so ran and deployed it like this: helm repo add utkuozdemir https://utkuozdemir.org/helm-charts helm install my-release utkuozdemir/filebrowser export POD_NAME = $( kubectl get pods kubernetes.io/name = filebrowser,app.ease \" -o jsonpath=\" { .items [ 0 ] .metadata.name } export CONTAINER_PORT = $( kubectl get pod E -o jsonpath = \"{.spec.containers0].ports[0]. echo \" Visit http://127.0.0.1:8080 to use kubectl --namespace default port-forward $POD_NAME 8080 : $CONTAINER_PORT From this I learned a couple of things: We can pull helm charts from the internet with a system of repos We can use xpath style queries to parse out bits of info from kubectl The last line gives some hints about how to foward traffic out of k8","title":"Personal Kubernetes Infrastructure"},{"location":"devops/infrastructure/personal_infrastructure/#personal-kubernetes-infrastructure","text":"","title":"Personal Kubernetes Infrastructure"},{"location":"devops/infrastructure/personal_infrastructure/#initial-setup","text":"This are initial notes from Tim on setting up a personal docker, rancher desktop and rancher server testbed environment. I started by setting up rancher desktop on my Fedora based linux laptop. I used the appimage (despite a concerning looking warning that firefox gives about the image when downloading it.) Here is the installation guide . Note: After upgrading to fedora 36 rancher desktop no longer started until I applied the following fix: https://github.com/rancher-sandbox/rancher-desktop/issues/2139#issuecomment-1114933138 Once installed I performed the following commands to do a quick start setup of nginx running in the k8 cluster. kubectl get nodes NAME STATUS ROLES AGE VERSION lima-rancher-desktop Ready control-plane,master 80m v1.22.7+k3s1 kubectl create deployment nginx --image = nginx deployment.apps/nginx created kubectl get pods NAME READY STATUS RESTARTS AGE nginx-6799fc88d8-7k4kd 0/1 ContainerCreating 0 10s kubectl describe nginx-6799fc88d8-7k4kd error: the server doesn't have a resource type \"nginx-6799fc88d8-7k4kd\" kubectl describe pod nginx-6799fc88d8-7k4kd Name: nginx-6799fc88d8-7k4kd Namespace: default Priority: 0 Node: lima-rancher-desktop/192.168.5.15 Start Time: Sat, 23 Apr 2022 22:57:06 +0100 Labels: app=nginx pod-template-hash=6799fc88d8 Annotations: none Status: Running IP: 10.42.0.9 IPs: IP: 10.42.0.9 Controlled By: ReplicaSet/nginx-6799fc88d8 Containers: nginx: > Container ID: containerd://f85e833716a254f9e981ebf6c0f432edab366aacdfa74cc46b84904e6afc8760 Image: nginx > Image ID: docker.io/library/nginx@sha256:859ab6768a6f26a79bc42b231664111317d095a4f04e4b6fe79ce37b3d199097 Port: none Host Port: none State: Running Started: Sat, 23 Apr 2022 22:57:23 +0100 Ready: True Restart Count: 0 Environment: none Mounts: > /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-hl4hc (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-hl4hc: > Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: nil DownwardAPI: true QoS Class: BestEffort Node-Selectors: none Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s > node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 33s default-scheduler Successfully assigned default/nginx-6799fc88d8-7k4kd to lima-rancher-desktop Normal Pulling 33s kubelet Pulling image \"nginx\" Normal Pulled 17s kubelet Successfully pulled image \"nginx\" in 16.398944871s Normal Created 17s kubelet Created container nginx Normal Started 16s kubelet Started container nginx kubectl get pods NAME READY STATUS RESTARTS AGE nginx-6799fc88d8-7k4kd 1/1 Running 0 44s kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-6799fc88d8-7k4kd 1/1 Running 0 57s 10.42.0.9 lima-rancher-desktop none none kubectl exec -it nginx-6799fc88d8-7k4kd /bin/sh kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future > > version. Use kubectl exec [POD] -- [COMMAND] instead. curl 10 .42.0.9 Welcome to nginx! html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } Welcome to nginx! If you see this page, the nginx web server is successfully installed and working. Further configuration is required. For online documentation and support please refer to nginx.org Commercial support is available at nginx.com Thank you for using nginx.","title":"Initial Setup"},{"location":"devops/infrastructure/personal_infrastructure/#exit","text":"kubectl get pods `` > NAME READY STATUS RESTARTS AGE > nginx-6799fc88d8-7k4kd 1 /1 Running 0 2m45s These steps are verbatim from [ this youtube video ]( https://www.youtube.com/watch?v = LwE8IA3glE4 ) . From this initial run through we can assume these basic concepts: ! [ K8 Concepts ]( img/k8-concepts.png ) ## Deploying Rancher on Rancher Desktop I remember that Dominic explained about namespaces in his initial walk through so let me try to create a new namespace. ``` bash kubectl create namespace tim While trying to figure out how to list my namespaces, I found this nice k8 cheatsheet . The above cheatsheet didnt actually contain the tip I needed but a bit of googling came up with this: kubectl get namespaces --show-labels NAME STATUS AGE LABELS default Active 141m kubernetes.io/metadata.name=default kube-system Active 141m kubernetes.io/metadata.name=kube-system kube-public Active 141m kubernetes.io/metadata.name=kube-public kube-node-lease Active 141m kubernetes.io/metadata.name=kube-node-lease tim Active 3m34s kubernetes.io/metadata.name=tim You can see my tim namespace listed as the last entry there. So based on doing that, I think I can update my concept diagram to look like this: kubectl apiVersion: v1 kind: Pod metadata: name: nginxpod namespace: tim labels: name: nginxpod spec: containers: name: web image: nginx I saved the above as nginx.yml and was able to run it like this: kubectl apply -f nginx.yml Then I could check in the tim namespace to see if it was running: kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system local-path-provisioner-84bb864455-dsv47 1/1 Running 0 150m kube-system helm-install-traefik-crd--1-xrhvf 0/1 Completed 0 150m kube-system svclb-traefik-p9zwj 2/2 Running 0 150m kube-system helm-install-traefik--1-m2r2x 0/1 Completed 1 150m kube-system coredns-96cc4f57d-5bzj8 1/1 Running 0 150m kube-system traefik-56c4b88c4b-mpwfm 1/1 Running 0 150m kube-system metrics-server-ff9dbcb6c-6gzt5 1/1 Running 0 150m default nginx-6799fc88d8-7k4kd 1/1 Running 0 69m tim nginxpod 1/1 Running 0 14s We can see my nginx pod in my namespace as the last entry.","title":"exit"},{"location":"devops/infrastructure/personal_infrastructure/#installing-rancher-on-rancher-desktop","text":"I went here for instructions. helm repo add rancher-latest https://releases.rancher.com/server-charts/latest kubectl create namespace cattle-system helm install rancher rancher-latest/rancher --namespace cattle-system --set hostname = crest --set replicas = 1 --set ingress.tls.source = secret A little note here: the above tutorial provides different pathways to get a certificate. I am using ingress.tls.source=secret because I am just running on my local sytstem. In production you probably want to use a different option. Also I reduced replicas to 1 since I only have 1 pod in my local test environment. After running, I got a nice message saying rancher is setting itself up: NAME: rancher LAST DEPLOYED: Sun Apr 24 11:25:45 2022 NAMESPACE: cattle-system STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: Rancher Server has been installed. NOTE: Rancher may take several minutes to fully initialize. Please standby while Certificates are being issued, Containers are started and the Ingress rule comes up. Check out our docs at https://rancher.com/docs/ If you provided your own bootstrap password during installation, browse to https://crest to get started. If this is the first time you installed Rancher, get started by running this command and clicking the URL it generates: echo https://crest/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}') To get just the bootstrap password on its own, run: kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}{{ \"\\n\" }}' Happy Containering! ``` Let's use our experience from the simple nginx deployment to see what is running on the system now: kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system helm-install-traefik-crd--1-xrhvf 0/1 Completed 0 13h kube-system helm-install-traefik--1-m2r2x 0/1 Completed 1 13h kube-system svclb-traefik-p9zwj 2/2 Running 2 (10m ago) 13h kube-system local-path-provisioner-84bb864455-dsv47 1/1 Running 1 (10m ago) 13h kube-system coredns-96cc4f57d-5bzj8 1/1 Running 1 (10m ago) 13h tim nginxpod 1/1 Running 1 (10m ago) 11h default nginx-6799fc88d8-7k4kd 1/1 Running 1 (10m ago) 12h kube-system traefik-56c4b88c4b-mpwfm 1/1 Running 1 (10m ago) 13h kube-system metrics-server-ff9dbcb6c-6gzt5 1/1 Running 1 (10m ago) 13h cattle-system rancher-6448c4dcdf-8wpsk 1/1 Running 0 3m37s cattle-fleet-system gitjob-cc9948fd7-jxgg5 1/1 Running 0 44s cattle-fleet-system fleet-controller-5746685958-f4rx5 1/1 Running 0 44s cattle-system helm-operation-zfbfq 0/2 Completed 0 68s cattle-system helm-operation-5sg9s 0/2 Completed 0 16s cattle-system helm-operation-n6ggh 2/2 Running 0 10s cattle-fleet-local-system fleet-agent-6c6c8c45f8-vtbnm 0/1 ContainerCreating 0 7s cattle-system rancher-webhook-6958cfcddf-z9rxr 0/1 ContainerCreating 0 5s We can see various jobs are still spinning up in the cattle-system. Next I went on a little detour on creating a self signed certificate that I can install in my rancher instance. openssl req -new -newkey rsa:4096 -x509 -sha256 -days 365 \\ -nodes -out tls.crt -keyout tls.key Note: I believe it is required to name the key tls.* so as to match the secret name. Which outputs this: Generating a RSA private key writing new private key to 'tls.key' You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. Country Name (2 letter code) [XX]:pt State or Province Name (full name) []: Locality Name (eg, city) [Default City]: Organization Name (eg, company) [Default Company Ltd]: Organizational Unit Name (eg, section) []: Common Name (eg, your name or your server's hostname) []: Email Address []:tim@kartoza.com Then we have two certs in our directory: ls tls.crt tls.key nginx.yml Then on this rancher page , I followed these notes to install my cert: kubectl -n cattle-system create secret tls tls-rancher-ingress \\ --cert = tls.crt \\ --key = tls.key secret/tls-rancher-ingress created Ok then back to the main thread of the rancher installation tutorial I continued: kubectl -n cattle-system rollout status deploy/rancher Which returns this: deployment \"rancher\" successfully rolled out","title":"Installing Rancher on Rancher Desktop"},{"location":"devops/infrastructure/personal_infrastructure/#testing-it-out","text":"The instructions say to open the host in your browser (in my case I used my local hostname of crest), but nothing opened. I took a look in rancher desktop and played with the port forwarding. The default install looked like this: So I went ahead and tried to forward that rancher port: Then tried to open https://localhost:37443/ Which gave me an error: The thing seems to be that you need to rather forward this port: Then I was able ot open the site (different port number now) an set up my credentials following the hints provided. Note : Since I am using a self signed cert I had to do the normal firefox security warning process to proceed to the site. I did however still have some errors now showing in rancher:","title":"Testing it out"},{"location":"devops/infrastructure/personal_infrastructure/#deploying-a-small-application-from-a-helm-chart","text":"I know helm charts are like the package managers of kubernetes, but I am not familiar with them, so I went to make a small test with the filebrowser.org (awesome app btw). I found these instructions and so ran and deployed it like this: helm repo add utkuozdemir https://utkuozdemir.org/helm-charts helm install my-release utkuozdemir/filebrowser export POD_NAME = $( kubectl get pods kubernetes.io/name = filebrowser,app.ease \" -o jsonpath=\" { .items [ 0 ] .metadata.name } export CONTAINER_PORT = $( kubectl get pod E -o jsonpath = \"{.spec.containers0].ports[0]. echo \" Visit http://127.0.0.1:8080 to use kubectl --namespace default port-forward $POD_NAME 8080 : $CONTAINER_PORT From this I learned a couple of things: We can pull helm charts from the internet with a system of repos We can use xpath style queries to parse out bits of info from kubectl The last line gives some hints about how to foward traffic out of k8","title":"Deploying a small application from a helm chart"},{"location":"devops/infrastructure/rancher-k3s-single-node/","text":"Using Rancher, K3S, and Longhorn for single node Kubernetes deployment \u00b6 Prerequisites: This process assumes the use of a clean Ubuntu 20.04 server with a public IP address and an authorized key recognised by the server in the current users ~/.ssh. Rancher Deployment Process \u00b6 Get the docker-ansible project to run an ansible controller in a docker container user@dev$ git clone https://github.com/kartoza/docker-ansible.git Build the container image user@dev$ cd docker-ansible user@dev$ docker build . -t ansible Replace the remote IP address in the inventory file user@dev$ echo \"<server-ip> ansible_user=root ansible_private_key_file=/root/.ssh/id_ed25519\" > ${ PWD } /ansible/inventory/hosts.ini Remove the default playbooks directory user@dev$ rm -r ./ansible/playbooks Fetch the playbook repository which includes the singlenode rancher deployment user@dev$ cd ./ansible && git clone https://github.com/kartoza/playbooks.git Go back to the repository root user@dev$ cd /.. Run the docker container (Powershell/ Windows users should read the docker-ansible readme) user@dev$ docker run -dt -v $PWD /ansible:/ansible \\ -v ~/.ssh:/root/win-ssh:ro \\ -e ANSIBLE_CONFIG = /ansible/ansible.cfg \\ --restart = unless-stopped \\ --name ansible ansible Once the container is running run the playbook user@dev$ docker exec -it ansible ansible-playbook /ansible/playbooks/ubuntu20.04/app/rancher-singlenode.yaml Save the logs and kill off the ansible container user@dev$ docker logs ansible >> $PWD /ansible_log.txt && docker rm -f ansible At this point, the server should be configured to use https://rancher.<server-ip>.sslip.io . By default the admin user is admin and the password is chickensoup but that can be changed in the rancher-singlenode.yaml file. Note self-signed TLS is enabled so there'll be browser notices, but TLS configuration is environment specific and not considered in the scope of this process definition. Application Deployment Process \u00b6 Now the project workload will need to be deployed to the server. This will use kubectl and can be done in various ways. If you wish to deploy from the local machine, the kubectl configuration for each node should be available in the ansible/data directory. For the purpose of demonstrating this process, it is assumed that this is done by using ssh to connect to the server as the root user, which should have the kubectl configuration already setup by the ansible deployment. user@dev$ ssh root@<server-ip> Clone the project repository root@app-srv$ mkdir /manifests && cd /manifests && git clone https://gitlab.com/zacharlie/test-manifest.git Replace the hostname field in the ingress with the fully qualified domain name of the server. root@app-srv$ cp /manifests/test-manifest/ingress.yaml /manifests/test-manifest/ingress.yaml.bak && awk '/nginx.test.localhost/ {sub(\"nginx.test.localhost\", \"123.456.7.89.sslip.io\", $0)} {print}' /manifests/test-manifest/ingress.yaml.bak > /manifests/test-manifest/ingress.yaml Apply the project resources using kustomize root@app-srv$ cd /manifests/test-manifest && kubectl apply -k . Be patient and monitor the resources from the nifty rancher dashboard (Workload >> Pods is a good place to start). Once everything is running you may view the landing page at the hostname address that was configured within the ingress configuration.","title":"Using Rancher, K3S, and Longhorn for single node Kubernetes deployment"},{"location":"devops/infrastructure/rancher-k3s-single-node/#using-rancher-k3s-and-longhorn-for-single-node-kubernetes-deployment","text":"Prerequisites: This process assumes the use of a clean Ubuntu 20.04 server with a public IP address and an authorized key recognised by the server in the current users ~/.ssh.","title":"Using Rancher, K3S, and Longhorn for single node Kubernetes deployment"},{"location":"devops/infrastructure/rancher-k3s-single-node/#rancher-deployment-process","text":"Get the docker-ansible project to run an ansible controller in a docker container user@dev$ git clone https://github.com/kartoza/docker-ansible.git Build the container image user@dev$ cd docker-ansible user@dev$ docker build . -t ansible Replace the remote IP address in the inventory file user@dev$ echo \"<server-ip> ansible_user=root ansible_private_key_file=/root/.ssh/id_ed25519\" > ${ PWD } /ansible/inventory/hosts.ini Remove the default playbooks directory user@dev$ rm -r ./ansible/playbooks Fetch the playbook repository which includes the singlenode rancher deployment user@dev$ cd ./ansible && git clone https://github.com/kartoza/playbooks.git Go back to the repository root user@dev$ cd /.. Run the docker container (Powershell/ Windows users should read the docker-ansible readme) user@dev$ docker run -dt -v $PWD /ansible:/ansible \\ -v ~/.ssh:/root/win-ssh:ro \\ -e ANSIBLE_CONFIG = /ansible/ansible.cfg \\ --restart = unless-stopped \\ --name ansible ansible Once the container is running run the playbook user@dev$ docker exec -it ansible ansible-playbook /ansible/playbooks/ubuntu20.04/app/rancher-singlenode.yaml Save the logs and kill off the ansible container user@dev$ docker logs ansible >> $PWD /ansible_log.txt && docker rm -f ansible At this point, the server should be configured to use https://rancher.<server-ip>.sslip.io . By default the admin user is admin and the password is chickensoup but that can be changed in the rancher-singlenode.yaml file. Note self-signed TLS is enabled so there'll be browser notices, but TLS configuration is environment specific and not considered in the scope of this process definition.","title":"Rancher Deployment Process"},{"location":"devops/infrastructure/rancher-k3s-single-node/#application-deployment-process","text":"Now the project workload will need to be deployed to the server. This will use kubectl and can be done in various ways. If you wish to deploy from the local machine, the kubectl configuration for each node should be available in the ansible/data directory. For the purpose of demonstrating this process, it is assumed that this is done by using ssh to connect to the server as the root user, which should have the kubectl configuration already setup by the ansible deployment. user@dev$ ssh root@<server-ip> Clone the project repository root@app-srv$ mkdir /manifests && cd /manifests && git clone https://gitlab.com/zacharlie/test-manifest.git Replace the hostname field in the ingress with the fully qualified domain name of the server. root@app-srv$ cp /manifests/test-manifest/ingress.yaml /manifests/test-manifest/ingress.yaml.bak && awk '/nginx.test.localhost/ {sub(\"nginx.test.localhost\", \"123.456.7.89.sslip.io\", $0)} {print}' /manifests/test-manifest/ingress.yaml.bak > /manifests/test-manifest/ingress.yaml Apply the project resources using kustomize root@app-srv$ cd /manifests/test-manifest && kubectl apply -k . Be patient and monitor the resources from the nifty rancher dashboard (Workload >> Pods is a good place to start). Once everything is running you may view the landing page at the hostname address that was configured within the ingress configuration.","title":"Application Deployment Process"},{"location":"devops/procedures/","text":"DevOps Procedures \u00b6 DevOps tasks are handled by the DevOps board","title":"Procedures"},{"location":"devops/procedures/#devops-procedures","text":"DevOps tasks are handled by the DevOps board","title":"DevOps Procedures"},{"location":"devops/security/","text":"Security \u00b6 Cyber Hygiene Handbook Security Guidelines/ Rules Development Processes External Resources Cyber Hygiene Handbook \u00b6 'twould be handy to collect resources and advice on training users in best practices for cyber-hygiene (applies in broad strokes to staff, trainees, community, and more). Compiled into a nice concise resource with pretty pictures and minimal complexity++ Topics and structure could be outlined as follows: Users: Identifying phishing attacks Credential management Admins: Identifying whats on the network Account management Staying up to date Developers: Authentication management Dependency management Scanning SSH, SSL, SSO (lots of SS), Cryptography, Hashes, Salts","title":"Security"},{"location":"devops/security/#security","text":"Cyber Hygiene Handbook Security Guidelines/ Rules Development Processes External Resources","title":"Security"},{"location":"devops/security/#cyber-hygiene-handbook","text":"'twould be handy to collect resources and advice on training users in best practices for cyber-hygiene (applies in broad strokes to staff, trainees, community, and more). Compiled into a nice concise resource with pretty pictures and minimal complexity++ Topics and structure could be outlined as follows: Users: Identifying phishing attacks Credential management Admins: Identifying whats on the network Account management Staying up to date Developers: Authentication management Dependency management Scanning SSH, SSL, SSO (lots of SS), Cryptography, Hashes, Salts","title":"Cyber Hygiene Handbook"},{"location":"devops/security/links/","text":"Security: Useful Links \u00b6 A bunch of useful external resources related to security. Articles \u00b6 https://security-list.js.org/#/ https://www.sentinelone.com/blog/practice-these-10-basic-cyber-hygiene-tips-for-risk-mitigation/ Tools \u00b6 Projects which are good for security. https://keepass.info/ https://bitwarden.com/ https://pypi.org/project/xkcd-pass/ https://snyk.io/ https://docs.docker.com/engine/scan/ https://github.com/trailofbits/pip-audit https://github.com/trufflesecurity/trufflehog https://github.com/danielmiessler/SecLists","title":"Security: Useful Links"},{"location":"devops/security/links/#security-useful-links","text":"A bunch of useful external resources related to security.","title":"Security: Useful Links"},{"location":"devops/security/links/#articles","text":"https://security-list.js.org/#/ https://www.sentinelone.com/blog/practice-these-10-basic-cyber-hygiene-tips-for-risk-mitigation/","title":"Articles"},{"location":"devops/security/links/#tools","text":"Projects which are good for security. https://keepass.info/ https://bitwarden.com/ https://pypi.org/project/xkcd-pass/ https://snyk.io/ https://docs.docker.com/engine/scan/ https://github.com/trailofbits/pip-audit https://github.com/trufflesecurity/trufflehog https://github.com/danielmiessler/SecLists","title":"Tools"},{"location":"gis/","text":"GIS \u00b6 Resources, information, and processes related to Geographic Information Systems Note that all users, regardless of role, should understand and review the security section. GIS is a core competency at Kartoza. All technical staff should endeavour to ensure that they have or develop some level of proficiency in GIS. Cartography Technologies Resources","title":"GIS"},{"location":"gis/#gis","text":"Resources, information, and processes related to Geographic Information Systems Note that all users, regardless of role, should understand and review the security section. GIS is a core competency at Kartoza. All technical staff should endeavour to ensure that they have or develop some level of proficiency in GIS. Cartography Technologies Resources","title":"GIS"},{"location":"gis/cartography/","text":"Cartography \u00b6 Guidelines on how to create effective cartography . Information on the development of cartographic style guides.","title":"Cartography"},{"location":"gis/cartography/#cartography","text":"Guidelines on how to create effective cartography . Information on the development of cartographic style guides.","title":"Cartography"},{"location":"gis/cartography/cartography-guidelines/","text":"Cartography Guidelines \u00b6 This section is a collection of rules and mantras used by Kartoza to Make beautifull and effective catography. Tim's three principles \u00b6 In the above image we can see a framework for you to use to develop your cartography skills. There are three principles you should understand in order to make great cartographic products. The principles are an adaptable construct designed to help you make maps which respect your user's intelligence and surprise, excite and delight them. Process: This is definition of a standardised, rigourous set of steps that should be followed by for yourself and / or your co-workers to adhere to when developing your product. Process is the unexciting stuff that happens in the background. Your process should be defined as a nest list of statements. The best way to explain is by an example: All map fonts should be at least or larger than 6pt. All map symbols should be at least or larger than 3mm. All third party map symbols should available published under an open license. .... etc. .... The development of the process is to have the creation of your map repeatable from one end to another, and to be able to work collaboratively with colleages in a consistent way. Technical Skill : This is the process whereby you learn the capabilities of the software (e.g. QGIS) as thoroughly as possible in order to be able to articulate any idea you or others may have as a cartographic expression. Technical skill is a process of continual learning and acquiring it should commence with the development of a high level framework of the cartographi system and then progress with a deeper and deeper understanding of all of the constituent parts. Creativity: This is the hardest (and sometimes impossible) to imbue in a cartographer. When you lack personal creativity to come up with great map designs, you should (ethically) build on the work of others through emulation. By ethically we mean, crediting the inspiration of your designs to the correct person, asking permission when needed, and being sensitive to the livelhood and reputation for whoever you derive your work from. When you do have a creative side, you should be using it to inform the process and learning of technical skills so that you can articulate your vision in the cartography you produces. We should stress that all rules you or others create can be broken if they are broken with intention. That is to say, if you decide a 3 point font symbol is critical for the artistic or technical vision, you should not be afraid to make such a decision. What we want to avoid is unintentional breaking of your own rules as it will lead to a less professional looking product. The relative size of your circles for process versus creative versus technical abilities will likely differ widelines. Your job is to strive in your personal journey as a cartographyer to bring them into good proportion and to grow the areas which are under developed. There is a lot of theory out there on cartographic design, but I really recommend reading this wikipedia page: https://en.wikipedia.org/wiki/Cartographic_design and also reading the QGIS Map Design book by Anita Graser and Gretchen Peterson ( available at https://locatepress.com/book/qmd2 ). . Steps to preparing a map \u00b6 Choose your locality. Perhaps you have a client or an assignment which will determine the place. Or perhaps you have the feedom to choose the place yourself. Choose the scale for your map. Again this may be client driven based on a specification or you might have the freedom to choose yourself. But decide up front what scale you will view the map at as it will influence all your decisions as you develop your map. In some cases you may be asked to make a variable scale product e.g. for a web map that can be zoomed in and out. If you are producing a variable scale map, determine which scale ranges and intervals will be used. For example, OpenStreetMap defines standard scale intervals which are used by many web web mapping toolkits. If you are able to choose your own scale, try to choose a humanistic scale e.g. 1:50 0000, 1:5000 etc. Assuming you are preparing a fixed scale map, define the extent of your map . This may be determined by the print page size or by client factors. In some cases, the size of the print medium may influence the scale of your map. For example, you may be printing to an A4 map and need to choose a scale that allows you to see the whole town or area of interest. Determine which data layers to feature in your map . Some typical examples will be roads, buildings, rivers, water bodies, points of interest etc. Make a list and then go out and procure your data. For each dataset your find, keep note of the following details in a spreadsheet or notes file: Date of download Source (name of person or organisation) Attribution (citation for the data) URL Notes Determine the purpose of your map. Every map has a story to tell. Maybe you want to show a tourist around your city? Perhaps it is a narrative about crime or socio-economics. Try to create a short narrative like you were telling a friend about visiting the place in your map to create a sense of 'feel' about the place. Plan your colour palette. Overwhelming your reader with many, jarring colours won't help them to interpret your map well, not will it make for an aesthetically pleaseing experience. If you are not good at working with colours, find a photo of a key feature of the area and lift colours out of the image until you have about 8 to 10 colours of different hues and intensities. Or check out one of the many online sites like coolers.co . Choose a style. There are many amazing cartographic styles out there. Do you want something technical? Cartoony? Medieval looking? Find an example of a similar style to what you have in mind and look at what visual elements they use to cartography style. - Medieval Mappa Mundi map from the 1300s ( source - Wikipedia ) Plan your layout. If you are making a print map, it can be useful to roughly plan where all the elements such as map, legend, photos or graphics etc. will appear on your layout. That will influence some decisions in your cartography and will help you to organise your work plan. Create a set of guidelines. Create some rules for yourself to follow. Life gets a lot easier when you have a framework to construct your work on than when you are just 'winging it'. Use the QGIS QuickOSM Plugin to quickly establish a baseline set of layers for your map. . Mantras \u00b6 The user should not be exposed to the inner workings of the system. With is guideline we try to avoid asking the user to perform activities that presume or require that they have inside knowledge of how the system works. Where breaking this guideline is unavoidable, such tasks should be well described so as to allow the user to carry out the task with the least possible friction. If you use somebody else's work, they should be attributed unless they do not require it. Get peer review of your work early and often. Keep to the topic of your creation. Speak to your audience. Think of your work from the user's point of view and create something they can relate to. Follow the principle of separation of concerns. Users should have a clear understanding of where they are in a workflow, being presented with information which is thematic to the task at hand, whilst non-relevant questions or information should be hidden. Use emphasis sparingly. If everything is emphasised, nothing is emphasised! Some things that provide emphasis are . Layout visual elements in a consistent way in terms of size, colour and spacing. Break this rule with intention. . Tell a story! Make sure the user understands why they are here. Explicit is better than implicit. Don't assume your users know about simple things like north direction etc. Design the system to be easy to maintain. In this case, the map should avoid introducing unneeded functionality, using unneeded infrastructure, include obfuscated or overly complex terms or visual imagery. To achieve this, we should strive for simplicity and clarity in the user experience. Don't present data, present insights. Pay extreme attention to detail to create a professional product. Pay extreme attention to detail to create a professional product. Reduce reduce reduce - prune the content until it has the minumum number of elements needed to convey your message. Make rules for yourself and follow them closely. Break your rules with intention. Create a consistent visual and interactive metaphor and using it throughout the system if possible. \"Obey the principle of least surprise\". Design to reduce cognative friction. Surpise and delight your user. There is no such thing as cheating, only finding creative solutions to your problems. Whenever possible, do things for the user. There is no such thing as cheating, only finding creative solutions to your problems. Choosing a Coordinate Reference System for your map \u00b6 The order of preference for selection of a CRS for your map should be determined by the intended purpose and by client requirements: Scale CRS Type CRS Notes Global Spherical IAU_2015:39965 Orthographic Use for inset maps or contextual maps. Create a customised CRS based on this to move the LO origin. Global Cylindrical EPSG:8857 Equal Earth Use for flat maps of the world. Represents country sizes fairly. See The Equal Earth Website . Any Spherical EPSG:3857 Spherical Use for maps destined for the web or that incorporate data from online sources like MapTiler or OSM tiles. Regional Conic EPSG:102024 Lambert Use for maps covering a large East-West area. For example spanning 3 or 4 UTM zones. Local Mercator EPSG:32XXXX UTM Use for maps covering small, local areas. For example spanning 1 or less UTM zones. Cartography Resources \u00b6 Name Description Oxford AI Textures Use for raster fill textures. License unknown. QGIS Styles A collection of re-usable QGIS styles you can use to level up your cartography and learn how to produce interesting cartography. QGIS Example Projects A collection of QGIS projects which provide reference examples of how different GIS workflows in QGIS. QGIS Example Processing Models A collection of processing models which solve different geospatial analysis problems. QGIS Example 3D Models A collection of 3d Objects you can use as point symbol markers for your 3D Scenes. QGIS .lyr Files A collection of QGIS .lyr files with useful datasets that you can add to your QGIS projects. Google Fonts A large collection of fonts you can use in your projects. We also deploy these fonts in OSGS too so if you make a web map they will be available there. GNU Fonts Another large set of free fonts you can use in your project. Common issues in cartography \u00b6 No. Image Description 1 Dont let labels overlap features. 2 Make sure that major roads cover minor roads. 3 Set your canvas scale to the scale you plan to print at 1\ufe0f\u20e3 then lock it 2\ufe0f\u20e3 then when you zoom in and out with your scroll wheel it will zoom into pixels at the fixed scale 3\ufe0f\u20e3. 4 Don't include roads on your map that end abruptly unless this indeed reflects reality. 5 Generally you should use a round cap style for your roads to avoid issues of the road cap extending beyond intersecting roads. 6 As a general rule, points should be drawn above polygon and line features. 7 Use a font that matches the language of your map. 8 Use symbol layers to place a solid background behind symbols which are transparent and are getting lost in the background. 9 Do not use transparency inappropriately. Features like dams should be usually rendered with a solid fill. 10 Avoid visual clutter in your map. If there are too many features visible with similar contrast your user will quickly become overwhelmed. 11 Avoid overlapping features that don't naturally overlap. 12 Use layer symbol levels for multilayer symbols to prevent elements of the style overlapping. 13 Don't use legend items that are not meaningful. 14 Use call out labels when they risk covering important features on the map. 15 Don't let line or polygon features obscure point symbols. 16 Make sure the sizes of components on your map are balanced. 17 Avoid side effects of using transparent colours. 18 Always run your text through a spelling and grammar checker. 19 Have someone else read your prose to ensure the phrasing is clear and easy to read. 20 Learn how to split legend columns to create a sense of balance in your composition. 21 Don't use light colours on a dark background, dark colours on a dark background. 22 Humanize all text shown to users (see mantra about exposing users to inner workings of the system). 23 Set up your rendering options so that your symbols are not partially drawn / clipped - unless this is by design. 24 Avoid having labels obscure the features they are labelling. 25 Make sure all elements are aligned with pixel perfect precision. 26 Ensure white space between elements is the same to create a sense of perfect symmetry. Using a layout grid can help a lot with this. 27 Avoid repeating labels on the same line segment unless it is by intention. 28 Where relevant, provide context at the edges of your map so the user understands where they will go if they leave the map. // : # (This is a comment it wont be rendered if you leave a blank line after) 1 | |","title":"Cartography Guidelines"},{"location":"gis/cartography/cartography-guidelines/#cartography-guidelines","text":"This section is a collection of rules and mantras used by Kartoza to Make beautifull and effective catography.","title":"Cartography Guidelines"},{"location":"gis/cartography/cartography-guidelines/#tims-three-principles","text":"In the above image we can see a framework for you to use to develop your cartography skills. There are three principles you should understand in order to make great cartographic products. The principles are an adaptable construct designed to help you make maps which respect your user's intelligence and surprise, excite and delight them. Process: This is definition of a standardised, rigourous set of steps that should be followed by for yourself and / or your co-workers to adhere to when developing your product. Process is the unexciting stuff that happens in the background. Your process should be defined as a nest list of statements. The best way to explain is by an example: All map fonts should be at least or larger than 6pt. All map symbols should be at least or larger than 3mm. All third party map symbols should available published under an open license. .... etc. .... The development of the process is to have the creation of your map repeatable from one end to another, and to be able to work collaboratively with colleages in a consistent way. Technical Skill : This is the process whereby you learn the capabilities of the software (e.g. QGIS) as thoroughly as possible in order to be able to articulate any idea you or others may have as a cartographic expression. Technical skill is a process of continual learning and acquiring it should commence with the development of a high level framework of the cartographi system and then progress with a deeper and deeper understanding of all of the constituent parts. Creativity: This is the hardest (and sometimes impossible) to imbue in a cartographer. When you lack personal creativity to come up with great map designs, you should (ethically) build on the work of others through emulation. By ethically we mean, crediting the inspiration of your designs to the correct person, asking permission when needed, and being sensitive to the livelhood and reputation for whoever you derive your work from. When you do have a creative side, you should be using it to inform the process and learning of technical skills so that you can articulate your vision in the cartography you produces. We should stress that all rules you or others create can be broken if they are broken with intention. That is to say, if you decide a 3 point font symbol is critical for the artistic or technical vision, you should not be afraid to make such a decision. What we want to avoid is unintentional breaking of your own rules as it will lead to a less professional looking product. The relative size of your circles for process versus creative versus technical abilities will likely differ widelines. Your job is to strive in your personal journey as a cartographyer to bring them into good proportion and to grow the areas which are under developed. There is a lot of theory out there on cartographic design, but I really recommend reading this wikipedia page: https://en.wikipedia.org/wiki/Cartographic_design and also reading the QGIS Map Design book by Anita Graser and Gretchen Peterson ( available at https://locatepress.com/book/qmd2 ). .","title":"Tim's three principles"},{"location":"gis/cartography/cartography-guidelines/#steps-to-preparing-a-map","text":"Choose your locality. Perhaps you have a client or an assignment which will determine the place. Or perhaps you have the feedom to choose the place yourself. Choose the scale for your map. Again this may be client driven based on a specification or you might have the freedom to choose yourself. But decide up front what scale you will view the map at as it will influence all your decisions as you develop your map. In some cases you may be asked to make a variable scale product e.g. for a web map that can be zoomed in and out. If you are producing a variable scale map, determine which scale ranges and intervals will be used. For example, OpenStreetMap defines standard scale intervals which are used by many web web mapping toolkits. If you are able to choose your own scale, try to choose a humanistic scale e.g. 1:50 0000, 1:5000 etc. Assuming you are preparing a fixed scale map, define the extent of your map . This may be determined by the print page size or by client factors. In some cases, the size of the print medium may influence the scale of your map. For example, you may be printing to an A4 map and need to choose a scale that allows you to see the whole town or area of interest. Determine which data layers to feature in your map . Some typical examples will be roads, buildings, rivers, water bodies, points of interest etc. Make a list and then go out and procure your data. For each dataset your find, keep note of the following details in a spreadsheet or notes file: Date of download Source (name of person or organisation) Attribution (citation for the data) URL Notes Determine the purpose of your map. Every map has a story to tell. Maybe you want to show a tourist around your city? Perhaps it is a narrative about crime or socio-economics. Try to create a short narrative like you were telling a friend about visiting the place in your map to create a sense of 'feel' about the place. Plan your colour palette. Overwhelming your reader with many, jarring colours won't help them to interpret your map well, not will it make for an aesthetically pleaseing experience. If you are not good at working with colours, find a photo of a key feature of the area and lift colours out of the image until you have about 8 to 10 colours of different hues and intensities. Or check out one of the many online sites like coolers.co . Choose a style. There are many amazing cartographic styles out there. Do you want something technical? Cartoony? Medieval looking? Find an example of a similar style to what you have in mind and look at what visual elements they use to cartography style. - Medieval Mappa Mundi map from the 1300s ( source - Wikipedia ) Plan your layout. If you are making a print map, it can be useful to roughly plan where all the elements such as map, legend, photos or graphics etc. will appear on your layout. That will influence some decisions in your cartography and will help you to organise your work plan. Create a set of guidelines. Create some rules for yourself to follow. Life gets a lot easier when you have a framework to construct your work on than when you are just 'winging it'. Use the QGIS QuickOSM Plugin to quickly establish a baseline set of layers for your map. .","title":"Steps to preparing a map"},{"location":"gis/cartography/cartography-guidelines/#mantras","text":"The user should not be exposed to the inner workings of the system. With is guideline we try to avoid asking the user to perform activities that presume or require that they have inside knowledge of how the system works. Where breaking this guideline is unavoidable, such tasks should be well described so as to allow the user to carry out the task with the least possible friction. If you use somebody else's work, they should be attributed unless they do not require it. Get peer review of your work early and often. Keep to the topic of your creation. Speak to your audience. Think of your work from the user's point of view and create something they can relate to. Follow the principle of separation of concerns. Users should have a clear understanding of where they are in a workflow, being presented with information which is thematic to the task at hand, whilst non-relevant questions or information should be hidden. Use emphasis sparingly. If everything is emphasised, nothing is emphasised! Some things that provide emphasis are . Layout visual elements in a consistent way in terms of size, colour and spacing. Break this rule with intention. . Tell a story! Make sure the user understands why they are here. Explicit is better than implicit. Don't assume your users know about simple things like north direction etc. Design the system to be easy to maintain. In this case, the map should avoid introducing unneeded functionality, using unneeded infrastructure, include obfuscated or overly complex terms or visual imagery. To achieve this, we should strive for simplicity and clarity in the user experience. Don't present data, present insights. Pay extreme attention to detail to create a professional product. Pay extreme attention to detail to create a professional product. Reduce reduce reduce - prune the content until it has the minumum number of elements needed to convey your message. Make rules for yourself and follow them closely. Break your rules with intention. Create a consistent visual and interactive metaphor and using it throughout the system if possible. \"Obey the principle of least surprise\". Design to reduce cognative friction. Surpise and delight your user. There is no such thing as cheating, only finding creative solutions to your problems. Whenever possible, do things for the user. There is no such thing as cheating, only finding creative solutions to your problems.","title":"Mantras"},{"location":"gis/cartography/cartography-guidelines/#choosing-a-coordinate-reference-system-for-your-map","text":"The order of preference for selection of a CRS for your map should be determined by the intended purpose and by client requirements: Scale CRS Type CRS Notes Global Spherical IAU_2015:39965 Orthographic Use for inset maps or contextual maps. Create a customised CRS based on this to move the LO origin. Global Cylindrical EPSG:8857 Equal Earth Use for flat maps of the world. Represents country sizes fairly. See The Equal Earth Website . Any Spherical EPSG:3857 Spherical Use for maps destined for the web or that incorporate data from online sources like MapTiler or OSM tiles. Regional Conic EPSG:102024 Lambert Use for maps covering a large East-West area. For example spanning 3 or 4 UTM zones. Local Mercator EPSG:32XXXX UTM Use for maps covering small, local areas. For example spanning 1 or less UTM zones.","title":"Choosing a Coordinate Reference System for your map"},{"location":"gis/cartography/cartography-guidelines/#cartography-resources","text":"Name Description Oxford AI Textures Use for raster fill textures. License unknown. QGIS Styles A collection of re-usable QGIS styles you can use to level up your cartography and learn how to produce interesting cartography. QGIS Example Projects A collection of QGIS projects which provide reference examples of how different GIS workflows in QGIS. QGIS Example Processing Models A collection of processing models which solve different geospatial analysis problems. QGIS Example 3D Models A collection of 3d Objects you can use as point symbol markers for your 3D Scenes. QGIS .lyr Files A collection of QGIS .lyr files with useful datasets that you can add to your QGIS projects. Google Fonts A large collection of fonts you can use in your projects. We also deploy these fonts in OSGS too so if you make a web map they will be available there. GNU Fonts Another large set of free fonts you can use in your project.","title":"Cartography Resources"},{"location":"gis/cartography/cartography-guidelines/#common-issues-in-cartography","text":"No. Image Description 1 Dont let labels overlap features. 2 Make sure that major roads cover minor roads. 3 Set your canvas scale to the scale you plan to print at 1\ufe0f\u20e3 then lock it 2\ufe0f\u20e3 then when you zoom in and out with your scroll wheel it will zoom into pixels at the fixed scale 3\ufe0f\u20e3. 4 Don't include roads on your map that end abruptly unless this indeed reflects reality. 5 Generally you should use a round cap style for your roads to avoid issues of the road cap extending beyond intersecting roads. 6 As a general rule, points should be drawn above polygon and line features. 7 Use a font that matches the language of your map. 8 Use symbol layers to place a solid background behind symbols which are transparent and are getting lost in the background. 9 Do not use transparency inappropriately. Features like dams should be usually rendered with a solid fill. 10 Avoid visual clutter in your map. If there are too many features visible with similar contrast your user will quickly become overwhelmed. 11 Avoid overlapping features that don't naturally overlap. 12 Use layer symbol levels for multilayer symbols to prevent elements of the style overlapping. 13 Don't use legend items that are not meaningful. 14 Use call out labels when they risk covering important features on the map. 15 Don't let line or polygon features obscure point symbols. 16 Make sure the sizes of components on your map are balanced. 17 Avoid side effects of using transparent colours. 18 Always run your text through a spelling and grammar checker. 19 Have someone else read your prose to ensure the phrasing is clear and easy to read. 20 Learn how to split legend columns to create a sense of balance in your composition. 21 Don't use light colours on a dark background, dark colours on a dark background. 22 Humanize all text shown to users (see mantra about exposing users to inner workings of the system). 23 Set up your rendering options so that your symbols are not partially drawn / clipped - unless this is by design. 24 Avoid having labels obscure the features they are labelling. 25 Make sure all elements are aligned with pixel perfect precision. 26 Ensure white space between elements is the same to create a sense of perfect symmetry. Using a layout grid can help a lot with this. 27 Avoid repeating labels on the same line segment unless it is by intention. 28 Where relevant, provide context at the edges of your map so the user understands where they will go if they leave the map. // : # (This is a comment it wont be rendered if you leave a blank line after) 1 | |","title":"Common issues in cartography"},{"location":"gis/resources/","text":"GIS Resources \u00b6 Where to find internal resource collections (projects, templates, data, assets etc) External resource links","title":"Resources"},{"location":"gis/resources/#gis-resources","text":"Where to find internal resource collections (projects, templates, data, assets etc) External resource links","title":"GIS Resources"},{"location":"gis/technologies/","text":"Technologies \u00b6 Outline of Key GIS Technologies that all GIS practitioners should be familiar with. Outline GIS technologies and concepts for developers to get up to speed quickly.","title":"Technologies"},{"location":"gis/technologies/#technologies","text":"Outline of Key GIS Technologies that all GIS practitioners should be familiar with. Outline GIS technologies and concepts for developers to get up to speed quickly.","title":"Technologies"},{"location":"library/","text":"Resources \u00b6 Cheatsheets External Resources Kartoza Media Center Tutorials","title":"Resources"},{"location":"library/#resources","text":"Cheatsheets External Resources Kartoza Media Center Tutorials","title":"Resources"},{"location":"library/cheatsheets/","text":"Cheatsheets \u00b6 This article is under heavy development and is not considered production ready Cheatsheets and snippets for important and common operations. PostgreSQL BASH Kubectl OSGeo4W","title":"Cheatsheets"},{"location":"library/cheatsheets/#cheatsheets","text":"This article is under heavy development and is not considered production ready Cheatsheets and snippets for important and common operations. PostgreSQL BASH Kubectl OSGeo4W","title":"Cheatsheets"},{"location":"library/cheatsheets/bash/","text":"Bash \u00b6 This article is under heavy development and is not considered production ready A shell is a computer program which exposes an operating system's services to a human user or other programs. The Bourne Again SHell (BASH) is a command-line interpreter that is commonly found in many UNIX based Operating Systems, and the term \"bash-scripting\" has become synonymous with the execution of UNIX commands. BusyBox \u00b6 BusyBox is a software suite that provides several Unix utilities in a single executable file. Where bash provides a way for commands to be executed, BusyBox provides access to the commands themselves. BusyBox is probably the minimal toolset you can expect to find on UNIX systems and is commonly found on everything from workstations to servers to IoT devices. Many fan-favorite commands, such as cat , ls , top , grep , awk , mount , and more are actually made available by the BusyBox installation. /bin/busybox --list-full Other system commands vary from installation to installation, so the more you can achieve with the BusyBox tools and no external dependencies, the more robust your scripts will be. Executing Scripts \u00b6 A script is a file that contains a sequence of commands that are executed by the shell. To run those commands it must be made executable. chmod +x /path/to/my-script.sh For the system to know what software an executable file must be run with, a shebang is used at the top of the file #!/bin/bash","title":"Bash"},{"location":"library/cheatsheets/bash/#bash","text":"This article is under heavy development and is not considered production ready A shell is a computer program which exposes an operating system's services to a human user or other programs. The Bourne Again SHell (BASH) is a command-line interpreter that is commonly found in many UNIX based Operating Systems, and the term \"bash-scripting\" has become synonymous with the execution of UNIX commands.","title":"Bash"},{"location":"library/cheatsheets/bash/#busybox","text":"BusyBox is a software suite that provides several Unix utilities in a single executable file. Where bash provides a way for commands to be executed, BusyBox provides access to the commands themselves. BusyBox is probably the minimal toolset you can expect to find on UNIX systems and is commonly found on everything from workstations to servers to IoT devices. Many fan-favorite commands, such as cat , ls , top , grep , awk , mount , and more are actually made available by the BusyBox installation. /bin/busybox --list-full Other system commands vary from installation to installation, so the more you can achieve with the BusyBox tools and no external dependencies, the more robust your scripts will be.","title":"BusyBox"},{"location":"library/cheatsheets/bash/#executing-scripts","text":"A script is a file that contains a sequence of commands that are executed by the shell. To run those commands it must be made executable. chmod +x /path/to/my-script.sh For the system to know what software an executable file must be run with, a shebang is used at the top of the file #!/bin/bash","title":"Executing Scripts"},{"location":"library/cheatsheets/kubectl/","text":"Kubectl \u00b6 This article is under heavy development and is not considered production ready Kubectl (Kubernetes Control) is a commandline utility for managing Kubernetes clusters. Kustomize \u00b6 Kustomize is a utility for building and \"patching\" complete resource definitions from a subset of information, allowing . There are a lot of declarative items within a set of Kubernetes resources that may be consistent and repeating these definitions would become rather redundant. An example would be all the resources in the project requiring the inclusion of the namespace element in the resource metadata. Not only is this redundancy inefficient to manage and control, but it also violates DRY principles that ensure our components are managed consistently and to prevent errors. Common operations \u00b6 To validate the current resource configurations, run kubectl kustomize , or pipe the output to a file with kubectl kustomize > output.yaml to create a single file with a complete set of the resource definitions available within the current directory. Apply the current directories manifests using kustomize with kubectl apply -k . , with . being the current directory and using a kustomize.yaml file to define the resources to apply. Use kubectl -n my-namespace get pods to list the pods in the my-namespace namespace. This is useful when you want to find a pod by name, so that you can execute the command directly against a pod that forms a particular service. You would have to be careful with your deployments naming conventions to avoid collisions, but it can be super handy to enhance your automation capabilities. $ nginx_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"nginx\" ) && \\ echo $nginx_pod If you're a sucker for punishment, you can accomplish a similar result with powershell. > $nginx_pod = ( kubectl -n my-namespace get pods | Select-String -Pattern \"nginx\" -SimpleMatch | select -first 1 | %{ ( $_ -split \"\\s+\" )[ 0 ]}) > Write-Output $nginx_pod This makes it trivial to copy data into a volume with kubectl nginx_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"nginx\" ) && \\ kubectl -n my-namespace cp ./configs/web/index.html $nginx_pod :/web/index.html Or execute commands such as a mapproxy cleanup mapproxy_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"mapproxy\" ) && \\ kubectl -n my-namespace exec $mapproxy_pod -- /bin/bash -c \"mapproxy-seed -s /mapproxy/seed.yaml -f /mapproxy/mapproxy.yaml -c 4 --cleanup=remove_complete_levels\" Or run the command in the background within the pod, such as a mapproxy seeding operation mapproxy_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"mapproxy\" ) && \\ kubectl -n my-namespace exec $mapproxy_pod -- /bin/bash -c \"mapproxy-seed -s /mapproxy/seed.yaml -f /mapproxy/mapproxy.yaml -c 4 > /dev/null 2> /dev/null &\" Helm \u00b6 Helm is a Kubernetes Native package manager that provides more complex management capabilities for k8s resources. Helm is a separate application from kubectl that must be installed on a system with access to the cluster via the ~/.kube/config file.","title":"Kubectl"},{"location":"library/cheatsheets/kubectl/#kubectl","text":"This article is under heavy development and is not considered production ready Kubectl (Kubernetes Control) is a commandline utility for managing Kubernetes clusters.","title":"Kubectl"},{"location":"library/cheatsheets/kubectl/#kustomize","text":"Kustomize is a utility for building and \"patching\" complete resource definitions from a subset of information, allowing . There are a lot of declarative items within a set of Kubernetes resources that may be consistent and repeating these definitions would become rather redundant. An example would be all the resources in the project requiring the inclusion of the namespace element in the resource metadata. Not only is this redundancy inefficient to manage and control, but it also violates DRY principles that ensure our components are managed consistently and to prevent errors.","title":"Kustomize"},{"location":"library/cheatsheets/kubectl/#common-operations","text":"To validate the current resource configurations, run kubectl kustomize , or pipe the output to a file with kubectl kustomize > output.yaml to create a single file with a complete set of the resource definitions available within the current directory. Apply the current directories manifests using kustomize with kubectl apply -k . , with . being the current directory and using a kustomize.yaml file to define the resources to apply. Use kubectl -n my-namespace get pods to list the pods in the my-namespace namespace. This is useful when you want to find a pod by name, so that you can execute the command directly against a pod that forms a particular service. You would have to be careful with your deployments naming conventions to avoid collisions, but it can be super handy to enhance your automation capabilities. $ nginx_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"nginx\" ) && \\ echo $nginx_pod If you're a sucker for punishment, you can accomplish a similar result with powershell. > $nginx_pod = ( kubectl -n my-namespace get pods | Select-String -Pattern \"nginx\" -SimpleMatch | select -first 1 | %{ ( $_ -split \"\\s+\" )[ 0 ]}) > Write-Output $nginx_pod This makes it trivial to copy data into a volume with kubectl nginx_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"nginx\" ) && \\ kubectl -n my-namespace cp ./configs/web/index.html $nginx_pod :/web/index.html Or execute commands such as a mapproxy cleanup mapproxy_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"mapproxy\" ) && \\ kubectl -n my-namespace exec $mapproxy_pod -- /bin/bash -c \"mapproxy-seed -s /mapproxy/seed.yaml -f /mapproxy/mapproxy.yaml -c 4 --cleanup=remove_complete_levels\" Or run the command in the background within the pod, such as a mapproxy seeding operation mapproxy_pod = $( kubectl -n my-namespace get pods | awk '{print $1}' | grep -m 1 -e \"mapproxy\" ) && \\ kubectl -n my-namespace exec $mapproxy_pod -- /bin/bash -c \"mapproxy-seed -s /mapproxy/seed.yaml -f /mapproxy/mapproxy.yaml -c 4 > /dev/null 2> /dev/null &\"","title":"Common operations"},{"location":"library/cheatsheets/kubectl/#helm","text":"Helm is a Kubernetes Native package manager that provides more complex management capabilities for k8s resources. Helm is a separate application from kubectl that must be installed on a system with access to the cluster via the ~/.kube/config file.","title":"Helm"},{"location":"library/cheatsheets/osgeo4w/","text":"OSGeo4W \u00b6 This article is under heavy development and is not considered production ready OSGeo4W is an initiative from osgeo.org for packaging OpenSource Geospatial Systems, which are typically designed on and for Linux based systems, in an easy to use process that allows these systems (such as GRASS, QGIS, and others) to function well on the Windows Platform and manage each system and its dependencies in an easy to use way. Legacy systems \u00b6 Note that OSGeo4W used to be called OSGeo4W for the 32-bit installation and OSGeo4W64 for the 64-bit installation. In 2021 a new OSGeo4W installer was created and support for legacy 32-bit systems was dropped. If you are using an older installation, it is highly recommended CLI \u00b6 OSGeo4W provides an isolated environment that keeps to the \"everything is a file\" philosophy of Linux systems. This means that all of the dependencies of the system are packaged within the OSGeo4W directory (typically \"C:\\OSGeo4W\"). This makes it easy to install and manage the system, however it also means that the windows environment doesn't know how to access these utilities all by itself. This means that using some commandline tools, like GDAL for example, will not be available by default. PS C :\\ Users \\ Username > Get-Command gdalinfo Get-Command : The term 'gdalinfo' is not recognized as a name of a cmdlet , function , script file , or executable program . Check the spelling of the name , or if a path was included , verify that the path is correct and try again . PS C :\\ Users \\ Username > cmd / k \"where gdalinfo\" INFO : Could not find files for the given pattern ( s ). To access the OSGeo4W environment, we simply need to \"call\" the OSGeo4W batch script which handles the environment for us. PS C :\\ Users \\ Username > cmd / k \"call C:/OSGeo4W/OSGeo4W.bat\" run o-help for a list of available commands C :\\ OSGeo4W > where gdalinfo C :\\ OSGeo4W \\ bin \\ gdalinfo . exe C :\\ OSGeo4W > o-help When you start an OSGeo4W application, like QGIS Desktop for example, it will handle this environment configuration for you. If, however, you are performing other operations, such as using the qgis_processing framework or GRASS commandline tools, you will need to configure this environment yourself.","title":"OSGeo4W"},{"location":"library/cheatsheets/osgeo4w/#osgeo4w","text":"This article is under heavy development and is not considered production ready OSGeo4W is an initiative from osgeo.org for packaging OpenSource Geospatial Systems, which are typically designed on and for Linux based systems, in an easy to use process that allows these systems (such as GRASS, QGIS, and others) to function well on the Windows Platform and manage each system and its dependencies in an easy to use way.","title":"OSGeo4W"},{"location":"library/cheatsheets/osgeo4w/#legacy-systems","text":"Note that OSGeo4W used to be called OSGeo4W for the 32-bit installation and OSGeo4W64 for the 64-bit installation. In 2021 a new OSGeo4W installer was created and support for legacy 32-bit systems was dropped. If you are using an older installation, it is highly recommended","title":"Legacy systems"},{"location":"library/cheatsheets/osgeo4w/#cli","text":"OSGeo4W provides an isolated environment that keeps to the \"everything is a file\" philosophy of Linux systems. This means that all of the dependencies of the system are packaged within the OSGeo4W directory (typically \"C:\\OSGeo4W\"). This makes it easy to install and manage the system, however it also means that the windows environment doesn't know how to access these utilities all by itself. This means that using some commandline tools, like GDAL for example, will not be available by default. PS C :\\ Users \\ Username > Get-Command gdalinfo Get-Command : The term 'gdalinfo' is not recognized as a name of a cmdlet , function , script file , or executable program . Check the spelling of the name , or if a path was included , verify that the path is correct and try again . PS C :\\ Users \\ Username > cmd / k \"where gdalinfo\" INFO : Could not find files for the given pattern ( s ). To access the OSGeo4W environment, we simply need to \"call\" the OSGeo4W batch script which handles the environment for us. PS C :\\ Users \\ Username > cmd / k \"call C:/OSGeo4W/OSGeo4W.bat\" run o-help for a list of available commands C :\\ OSGeo4W > where gdalinfo C :\\ OSGeo4W \\ bin \\ gdalinfo . exe C :\\ OSGeo4W > o-help When you start an OSGeo4W application, like QGIS Desktop for example, it will handle this environment configuration for you. If, however, you are performing other operations, such as using the qgis_processing framework or GRASS commandline tools, you will need to configure this environment yourself.","title":"CLI"},{"location":"library/cheatsheets/postgresql/","text":"PostgreSQL \u00b6 This article is under heavy development and is not considered production ready PostgreSQL best SQL -- Everyone who knows what's up PostgreSQL also known as Postgres, is a free and open-source relational database management system (RDBMS). The name comes from its succession of its predecessor, Ingres. You are now a database nerd... there's no turning back. SQL \u00b6 Structured Query Language (SQL) is a query language used to interact with databases. It is a \"standard\" language structure, although its implementation differs between implementations. It does more than just query as well (see the Language Structures section below). Each discrete action in SQL is called a \"statement\", which does something like retrieving the results of a query or creating a new record, and multiple statements can be bundled together into a transaction. Fortunately the key words used in SQL tend to be written in (mostly) plain english, so it's relatively easy to understand and pick up. Multiple statements, joins, and subqueries can also be used which is where things start to get complicated, and optimizing those operations (and the database) can get rather complex. Simple Query Structures \u00b6 Common queries \u00b6 Basic query SELECT col1 , col2 FROM schema . table WHERE col2 = 'value' ORDER BY col1 ; Aggregated query SELECT max ( col1 ), col2 FROM schema . table GROUP BY col2 HAVING col2 = 'value' ; LIMIT n OFFSET offset ; Basic joins SELECT col1 , col2 FROM table1 FULL OUTER JOIN table2 ON col1 Clone table \u00b6 Duplicate table with data CREATE TABLE new_table AS SELECT * FROM old_table ; Duplicate table structure CREATE TABLE new_table AS TABLE existing_table WITH NO DATA ; Replicate table using subset CREATE TABLE new_table AS SELECT * FROM existing_table WHERE condition ; psql \u00b6 Using the psql interactive terminal for postgresql. Note that the version of psql on the local system is likely required to be an equal or higher version than for any databases with which you intend on interacting. Installing psql \u00b6 psql is installed alongside postgresql on many systems, however if it is not expected that the local machine will run a database server, psql can be installed using postgresql client libraries. Debian sudo apt install postgresql-client Mac brew link --force libpq $ psql --help psql is the PostgreSQL interactive terminal. Usage: psql [OPTION]... [DBNAME [USERNAME]] General options: -c, --command=COMMAND run only single command (SQL or internal) and exit -d, --dbname=DBNAME database name to connect to (default: \"Username\") -f, --file=FILENAME execute commands from file, then exit -l, --list list available databases, then exit -v, --set=, --variable=NAME=VALUE set psql variable NAME to VALUE (e.g., -v ON_ERROR_STOP=1) -V, --version output version information, then exit -X, --no-psqlrc do not read startup file (~/.psqlrc) -1 (\"one\"), --single-transaction execute as a single transaction (if non-interactive) -?, --help[=options] show this help, then exit --help=commands list backslash commands, then exit --help=variables list special variables, then exit Input and output options: -a, --echo-all echo all input from script -b, --echo-errors echo failed commands -e, --echo-queries echo commands sent to server -E, --echo-hidden display queries that internal commands generate -L, --log-file=FILENAME send session log to file -n, --no-readline disable enhanced command line editing (readline) -o, --output=FILENAME send query results to file (or |pipe) -q, --quiet run quietly (no messages, only query output) -s, --single-step single-step mode (confirm each query) -S, --single-line single-line mode (end of line terminates SQL command) Output format options: -A, --no-align unaligned table output mode --csv CSV (Comma-Separated Values) table output mode -F, --field-separator=STRING field separator for unaligned output (default: \"|\") -H, --html HTML table output mode -P, --pset=VAR[=ARG] set printing option VAR to ARG (see \\pset command) -R, --record-separator=STRING record separator for unaligned output (default: newline) -t, --tuples-only print rows only -T, --table-attr=TEXT set HTML table tag attributes (e.g., width, border) -x, --expanded turn on expanded table output -z, --field-separator-zero set field separator for unaligned output to zero byte -0, --record-separator-zero set record separator for unaligned output to zero byte Connection options: -h, --host=HOSTNAME database server host or socket directory (default: \"local socket\") -p, --port=PORT database server port (default: \"5432\") -U, --username=USERNAME database user name (default: \"Username\") -w, --no-password never prompt for password -W, --password force password prompt (should happen automatically) abstract \"Basic psql commands\" \u00b6 Example psql connection: psql -U username -d database_name -h localhost -p 5432; Quit psql: \\q; List databases: \\l; Connect to database: \\c database_name; List schemas: \\dn; List tables: \\dt; List table info: \\d+ table_name; List functions: \\df; List views: \\dv; cli \u00b6 Additional command line tools for interacting with postgreql databases. Note that the version of cli tools on the local system is likely required to be an equal or higher version than for any databases with which you intend on interacting. CLI tools are typically installed along with postgresql. Please see the \"installing psql\" section above for instructions on how to install command line tools. pg_dump \u00b6 $ pg_dump --help pg_dump dumps a database as a text file or to other formats. Usage: pg_dump [OPTION]... [DBNAME] General options: -f, --file=FILENAME output file or directory name -F, --format=c|d|t|p output file format (custom, directory, tar, plain text (default)) -j, --jobs=NUM use this many parallel jobs to dump -v, --verbose verbose mode -V, --version output version information, then exit -Z, --compress=0-9 compression level for compressed formats --lock-wait-timeout=TIMEOUT fail after waiting TIMEOUT for a table lock --no-sync do not wait for changes to be written safely to disk -?, --help show this help, then exit Options controlling the output content: -a, --data-only dump only the data, not the schema -b, --blobs include large objects in dump -B, --no-blobs exclude large objects in dump -c, --clean clean (drop) database objects before recreating -C, --create include commands to create database in dump -E, --encoding=ENCODING dump the data in encoding ENCODING -n, --schema=PATTERN dump the specified schema(s) only -N, --exclude-schema=PATTERN do NOT dump the specified schema(s) -O, --no-owner skip restoration of object ownership in plain-text format -s, --schema-only dump only the schema, no data -S, --superuser=NAME superuser user name to use in plain-text format -t, --table=PATTERN dump the specified table(s) only -T, --exclude-table=PATTERN do NOT dump the specified table(s) -x, --no-privileges do not dump privileges (grant/revoke) --binary-upgrade for use by upgrade utilities only --column-inserts dump data as INSERT commands with column names --disable-dollar-quoting disable dollar quoting, use SQL standard quoting --disable-triggers disable triggers during data-only restore --enable-row-security enable row security (dump only content user has access to) --exclude-table-data=PATTERN do NOT dump data for the specified table(s) --extra-float-digits=NUM override default setting for extra_float_digits --if-exists use IF EXISTS when dropping objects --inserts dump data as INSERT commands, rather than COPY --load-via-partition-root load partitions via the root table --no-comments do not dump comments --no-publications do not dump publications --no-security-labels do not dump security label assignments --no-subscriptions do not dump subscriptions --no-synchronized-snapshots do not use synchronized snapshots in parallel jobs --no-tablespaces do not dump tablespace assignments --no-unlogged-table-data do not dump unlogged table data --on-conflict-do-nothing add ON CONFLICT DO NOTHING to INSERT commands --quote-all-identifiers quote all identifiers, even if not key words --rows-per-insert=NROWS number of rows per INSERT; implies --inserts --section=SECTION dump named section (pre-data, data, or post-data) --serializable-deferrable wait until the dump can run without anomalies --snapshot=SNAPSHOT use given snapshot for the dump --strict-names require table and/or schema include patterns to match at least one entity each --use-set-session-authorization use SET SESSION AUTHORIZATION commands instead of ALTER OWNER commands to set ownership Connection options: -d, --dbname=DBNAME database to dump -h, --host=HOSTNAME database server host or socket directory -p, --port=PORT database server port number -U, --username=NAME connect as specified database user -w, --no-password never prompt for password -W, --password force password prompt (should happen automatically) --role=ROLENAME do SET ROLE before dump If no database name is supplied, then the PGDATABASE environment variable value is used. Report bugs to <pgsql-bugs@lists.postgresql.org>. Backup with pg_dump \u00b6 pg_dump is a command line tool for backing up postgresql databases. Simple example in bash: pg_dump -U admin_user -x -n public -h localhost -p 5111 -d gis > data.sql Complex example in Windows: \"C:\\Program Files\\PostgreSQL\\14\\bin\\pg_dump.exe\" --file \"C:\\\\backup\\\\data.sql\" --host \"127.0.0.1\" --port \"5234\" --username \"admin_user\" --no-password --verbose --format=p --no-owner --no-privileges --no-tablespaces --no-unlogged-table-data --encoding \"UTF8\" --schema \"public\" \"database_name\" PostGIS \u00b6 PostGIS is a spatial extension for PostgreSQL that provides spatial functions and datatypes. Be sure to check out the reference documentation at https://postgis.net/ . SRIDs \u00b6 Spatial Reference Identifiers and Coordinate Reference System (CRS) management with PostGIS. Create Custom CRS Definitions Example using custom Albers EE Conic (Southern Africa) INSERT INTO spatial_ref_sys ( srid , proj4text ) VALUES ( 40030 , '+proj=aea +lat_0=0 +lon_0=25 +lat_1=-24 +lat_2=-33 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs' ); Use UpdateGeometrySRID to update geometry SRIDs. select UpdateGeometrySRID ( 'table_name' , 'geom' , 4326 ); Language Structures \u00b6 There are multiple \"categories\" in SQL which apply different functionalities to different entities within the database. These are Data Definition Language (DDL), Data Query Language (DQL), Data Manipulation Language (DML), Transaction Control Language (TCL), and Data Control Language (DCL). Very basically, the nomenclature (and therefore the command used) may change between entities, and this makes it clear to the user and the database which entity or object the function should apply to. For example, you might use the DELETE command to delete a record from the database, but you would use the DROP command to delete a table, because tables and records are seen as different entities within the database. You can also do a ROLLBACK in a transaction, but you can't do so with a record INSERT command directly. These definitions are, of course, not arbitrarily assigned, and databases are a mature and complex field of computer science, which is where these formal structures and definitions come into effect. Read more on the topic at geeksforgeeks.org .","title":"PostgreSQL"},{"location":"library/cheatsheets/postgresql/#postgresql","text":"This article is under heavy development and is not considered production ready PostgreSQL best SQL -- Everyone who knows what's up PostgreSQL also known as Postgres, is a free and open-source relational database management system (RDBMS). The name comes from its succession of its predecessor, Ingres. You are now a database nerd... there's no turning back.","title":"PostgreSQL"},{"location":"library/cheatsheets/postgresql/#sql","text":"Structured Query Language (SQL) is a query language used to interact with databases. It is a \"standard\" language structure, although its implementation differs between implementations. It does more than just query as well (see the Language Structures section below). Each discrete action in SQL is called a \"statement\", which does something like retrieving the results of a query or creating a new record, and multiple statements can be bundled together into a transaction. Fortunately the key words used in SQL tend to be written in (mostly) plain english, so it's relatively easy to understand and pick up. Multiple statements, joins, and subqueries can also be used which is where things start to get complicated, and optimizing those operations (and the database) can get rather complex.","title":"SQL"},{"location":"library/cheatsheets/postgresql/#simple-query-structures","text":"","title":"Simple Query Structures"},{"location":"library/cheatsheets/postgresql/#common-queries","text":"Basic query SELECT col1 , col2 FROM schema . table WHERE col2 = 'value' ORDER BY col1 ; Aggregated query SELECT max ( col1 ), col2 FROM schema . table GROUP BY col2 HAVING col2 = 'value' ; LIMIT n OFFSET offset ; Basic joins SELECT col1 , col2 FROM table1 FULL OUTER JOIN table2 ON col1","title":"Common queries"},{"location":"library/cheatsheets/postgresql/#clone-table","text":"Duplicate table with data CREATE TABLE new_table AS SELECT * FROM old_table ; Duplicate table structure CREATE TABLE new_table AS TABLE existing_table WITH NO DATA ; Replicate table using subset CREATE TABLE new_table AS SELECT * FROM existing_table WHERE condition ;","title":"Clone table"},{"location":"library/cheatsheets/postgresql/#psql","text":"Using the psql interactive terminal for postgresql. Note that the version of psql on the local system is likely required to be an equal or higher version than for any databases with which you intend on interacting.","title":"psql"},{"location":"library/cheatsheets/postgresql/#installing-psql","text":"psql is installed alongside postgresql on many systems, however if it is not expected that the local machine will run a database server, psql can be installed using postgresql client libraries. Debian sudo apt install postgresql-client Mac brew link --force libpq $ psql --help psql is the PostgreSQL interactive terminal. Usage: psql [OPTION]... [DBNAME [USERNAME]] General options: -c, --command=COMMAND run only single command (SQL or internal) and exit -d, --dbname=DBNAME database name to connect to (default: \"Username\") -f, --file=FILENAME execute commands from file, then exit -l, --list list available databases, then exit -v, --set=, --variable=NAME=VALUE set psql variable NAME to VALUE (e.g., -v ON_ERROR_STOP=1) -V, --version output version information, then exit -X, --no-psqlrc do not read startup file (~/.psqlrc) -1 (\"one\"), --single-transaction execute as a single transaction (if non-interactive) -?, --help[=options] show this help, then exit --help=commands list backslash commands, then exit --help=variables list special variables, then exit Input and output options: -a, --echo-all echo all input from script -b, --echo-errors echo failed commands -e, --echo-queries echo commands sent to server -E, --echo-hidden display queries that internal commands generate -L, --log-file=FILENAME send session log to file -n, --no-readline disable enhanced command line editing (readline) -o, --output=FILENAME send query results to file (or |pipe) -q, --quiet run quietly (no messages, only query output) -s, --single-step single-step mode (confirm each query) -S, --single-line single-line mode (end of line terminates SQL command) Output format options: -A, --no-align unaligned table output mode --csv CSV (Comma-Separated Values) table output mode -F, --field-separator=STRING field separator for unaligned output (default: \"|\") -H, --html HTML table output mode -P, --pset=VAR[=ARG] set printing option VAR to ARG (see \\pset command) -R, --record-separator=STRING record separator for unaligned output (default: newline) -t, --tuples-only print rows only -T, --table-attr=TEXT set HTML table tag attributes (e.g., width, border) -x, --expanded turn on expanded table output -z, --field-separator-zero set field separator for unaligned output to zero byte -0, --record-separator-zero set record separator for unaligned output to zero byte Connection options: -h, --host=HOSTNAME database server host or socket directory (default: \"local socket\") -p, --port=PORT database server port (default: \"5432\") -U, --username=USERNAME database user name (default: \"Username\") -w, --no-password never prompt for password -W, --password force password prompt (should happen automatically)","title":"Installing psql"},{"location":"library/cheatsheets/postgresql/#abstract-basic-psql-commands","text":"Example psql connection: psql -U username -d database_name -h localhost -p 5432; Quit psql: \\q; List databases: \\l; Connect to database: \\c database_name; List schemas: \\dn; List tables: \\dt; List table info: \\d+ table_name; List functions: \\df; List views: \\dv;","title":"abstract \"Basic psql commands\""},{"location":"library/cheatsheets/postgresql/#cli","text":"Additional command line tools for interacting with postgreql databases. Note that the version of cli tools on the local system is likely required to be an equal or higher version than for any databases with which you intend on interacting. CLI tools are typically installed along with postgresql. Please see the \"installing psql\" section above for instructions on how to install command line tools.","title":"cli"},{"location":"library/cheatsheets/postgresql/#pg_dump","text":"$ pg_dump --help pg_dump dumps a database as a text file or to other formats. Usage: pg_dump [OPTION]... [DBNAME] General options: -f, --file=FILENAME output file or directory name -F, --format=c|d|t|p output file format (custom, directory, tar, plain text (default)) -j, --jobs=NUM use this many parallel jobs to dump -v, --verbose verbose mode -V, --version output version information, then exit -Z, --compress=0-9 compression level for compressed formats --lock-wait-timeout=TIMEOUT fail after waiting TIMEOUT for a table lock --no-sync do not wait for changes to be written safely to disk -?, --help show this help, then exit Options controlling the output content: -a, --data-only dump only the data, not the schema -b, --blobs include large objects in dump -B, --no-blobs exclude large objects in dump -c, --clean clean (drop) database objects before recreating -C, --create include commands to create database in dump -E, --encoding=ENCODING dump the data in encoding ENCODING -n, --schema=PATTERN dump the specified schema(s) only -N, --exclude-schema=PATTERN do NOT dump the specified schema(s) -O, --no-owner skip restoration of object ownership in plain-text format -s, --schema-only dump only the schema, no data -S, --superuser=NAME superuser user name to use in plain-text format -t, --table=PATTERN dump the specified table(s) only -T, --exclude-table=PATTERN do NOT dump the specified table(s) -x, --no-privileges do not dump privileges (grant/revoke) --binary-upgrade for use by upgrade utilities only --column-inserts dump data as INSERT commands with column names --disable-dollar-quoting disable dollar quoting, use SQL standard quoting --disable-triggers disable triggers during data-only restore --enable-row-security enable row security (dump only content user has access to) --exclude-table-data=PATTERN do NOT dump data for the specified table(s) --extra-float-digits=NUM override default setting for extra_float_digits --if-exists use IF EXISTS when dropping objects --inserts dump data as INSERT commands, rather than COPY --load-via-partition-root load partitions via the root table --no-comments do not dump comments --no-publications do not dump publications --no-security-labels do not dump security label assignments --no-subscriptions do not dump subscriptions --no-synchronized-snapshots do not use synchronized snapshots in parallel jobs --no-tablespaces do not dump tablespace assignments --no-unlogged-table-data do not dump unlogged table data --on-conflict-do-nothing add ON CONFLICT DO NOTHING to INSERT commands --quote-all-identifiers quote all identifiers, even if not key words --rows-per-insert=NROWS number of rows per INSERT; implies --inserts --section=SECTION dump named section (pre-data, data, or post-data) --serializable-deferrable wait until the dump can run without anomalies --snapshot=SNAPSHOT use given snapshot for the dump --strict-names require table and/or schema include patterns to match at least one entity each --use-set-session-authorization use SET SESSION AUTHORIZATION commands instead of ALTER OWNER commands to set ownership Connection options: -d, --dbname=DBNAME database to dump -h, --host=HOSTNAME database server host or socket directory -p, --port=PORT database server port number -U, --username=NAME connect as specified database user -w, --no-password never prompt for password -W, --password force password prompt (should happen automatically) --role=ROLENAME do SET ROLE before dump If no database name is supplied, then the PGDATABASE environment variable value is used. Report bugs to <pgsql-bugs@lists.postgresql.org>.","title":"pg_dump"},{"location":"library/cheatsheets/postgresql/#backup-with-pg_dump","text":"pg_dump is a command line tool for backing up postgresql databases. Simple example in bash: pg_dump -U admin_user -x -n public -h localhost -p 5111 -d gis > data.sql Complex example in Windows: \"C:\\Program Files\\PostgreSQL\\14\\bin\\pg_dump.exe\" --file \"C:\\\\backup\\\\data.sql\" --host \"127.0.0.1\" --port \"5234\" --username \"admin_user\" --no-password --verbose --format=p --no-owner --no-privileges --no-tablespaces --no-unlogged-table-data --encoding \"UTF8\" --schema \"public\" \"database_name\"","title":"Backup with pg_dump"},{"location":"library/cheatsheets/postgresql/#postgis","text":"PostGIS is a spatial extension for PostgreSQL that provides spatial functions and datatypes. Be sure to check out the reference documentation at https://postgis.net/ .","title":"PostGIS"},{"location":"library/cheatsheets/postgresql/#srids","text":"Spatial Reference Identifiers and Coordinate Reference System (CRS) management with PostGIS. Create Custom CRS Definitions Example using custom Albers EE Conic (Southern Africa) INSERT INTO spatial_ref_sys ( srid , proj4text ) VALUES ( 40030 , '+proj=aea +lat_0=0 +lon_0=25 +lat_1=-24 +lat_2=-33 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs' ); Use UpdateGeometrySRID to update geometry SRIDs. select UpdateGeometrySRID ( 'table_name' , 'geom' , 4326 );","title":"SRIDs"},{"location":"library/cheatsheets/postgresql/#language-structures","text":"There are multiple \"categories\" in SQL which apply different functionalities to different entities within the database. These are Data Definition Language (DDL), Data Query Language (DQL), Data Manipulation Language (DML), Transaction Control Language (TCL), and Data Control Language (DCL). Very basically, the nomenclature (and therefore the command used) may change between entities, and this makes it clear to the user and the database which entity or object the function should apply to. For example, you might use the DELETE command to delete a record from the database, but you would use the DROP command to delete a table, because tables and records are seen as different entities within the database. You can also do a ROLLBACK in a transaction, but you can't do so with a record INSERT command directly. These definitions are, of course, not arbitrarily assigned, and databases are a mature and complex field of computer science, which is where these formal structures and definitions come into effect. Read more on the topic at geeksforgeeks.org .","title":"Language Structures"},{"location":"library/links/","text":"Links \u00b6 Links to interesting external resources","title":"Links"},{"location":"library/links/#links","text":"Links to interesting external resources","title":"Links"},{"location":"library/media/","text":"Kartoza Media Center \u00b6 Welcome to the Kartoza Media Center. Here you can find links to media releases, social media feeds, and notices from Kartoza (Pty) Ltd Kartoza.com GitHub Twitter DockerHub Newsletters","title":"Media"},{"location":"library/media/#kartoza-media-center","text":"Welcome to the Kartoza Media Center. Here you can find links to media releases, social media feeds, and notices from Kartoza (Pty) Ltd Kartoza.com GitHub Twitter DockerHub Newsletters","title":"Kartoza Media Center"},{"location":"library/media/newsletters/","text":"Resources \u00b6 2021 Newsletter","title":"Resources"},{"location":"library/media/newsletters/#resources","text":"2021 Newsletter","title":"Resources"},{"location":"library/tutorials/","text":"Tutorials \u00b6 Tutorials. General : General tutorials QGIS : Tutorials related to QGIS Links : Links to third party and external tutorials and learning resources","title":"Tutorials"},{"location":"library/tutorials/#tutorials","text":"Tutorials. General : General tutorials QGIS : Tutorials related to QGIS Links : Links to third party and external tutorials and learning resources","title":"Tutorials"},{"location":"library/tutorials/general/","text":"General Tutorials \u00b6 General Tutorials. Remote Meeting Software \u00b6 Using Zoom : Basics on using Zoom Remote Meeting Software Using Google Meet : Basics on using Google Meet Remote Meeting Software Using Jitsi : Basics on using Jitsi Remote Meeting Software Documentation \u00b6 MkDocs PDF : Generating PDF Documentation from this site Tools \u00b6 Git Primer : A light-but-functional introduction to the Git Version Control System Procedures \u00b6 Deployments with Docker-Ansible : How to set up, configure, and deploy to a new host with docker-ansible .","title":"General Tutorials"},{"location":"library/tutorials/general/#general-tutorials","text":"General Tutorials.","title":"General Tutorials"},{"location":"library/tutorials/general/#remote-meeting-software","text":"Using Zoom : Basics on using Zoom Remote Meeting Software Using Google Meet : Basics on using Google Meet Remote Meeting Software Using Jitsi : Basics on using Jitsi Remote Meeting Software","title":"Remote Meeting Software"},{"location":"library/tutorials/general/#documentation","text":"MkDocs PDF : Generating PDF Documentation from this site","title":"Documentation"},{"location":"library/tutorials/general/#tools","text":"Git Primer : A light-but-functional introduction to the Git Version Control System","title":"Tools"},{"location":"library/tutorials/general/#procedures","text":"Deployments with Docker-Ansible : How to set up, configure, and deploy to a new host with docker-ansible .","title":"Procedures"},{"location":"library/tutorials/general/docker-ansible-deployments/","text":"Docker Ansible \u00b6 Docker-Ansible is a project for running an ansible controller in a docker container. This allows the controller to be used on windows and avoids issues with environment specific configuration or possible collisions, making it possible to use ansible playbooks for consistent and reliable deployments on VPS and BareMetal instances. The Kartoza Playbooks is used for company maintained playbooks. Prerequisites \u00b6 Ensure beforehand that you have ssh access to the relevant host, and replace the relevant server details in the host config etc. as outlined in the following commans. By default, Docker-Ansible will attempt to use the ssh configuration files from the host to perform operations. Procedure \u00b6 The following example shows bash commands on how to create a new docker-based host. Ensure beforehand that you have ssh access to the host and replace the relevant server details in the host config etc. git clone https://github.com/kartoza/docker-ansible.git cd docker-ansible/ansible rm -r playbooks git clone https://github.com/kartoza/playbooks.git echo 123 .456.78.90 ansible_user = root ansible_private_key_file = /root/.ssh/id_ed25519 > inventory/hosts.ini cd .. docker build . -t ansible docker run -dt -v $PWD /ansible:/ansible \\ -v ~/.ssh:/root/.ssh:ro \\ -e ANSIBLE_CONFIG = /ansible/ansible.cfg \\ --restart = unless-stopped \\ --name ansible ansible docker exec -it ansible ansible-playbook /ansible/playbooks/ubuntu20.04/app/docker-ce.yaml -u iamgroot -k Cleanup \u00b6 Once the task has run to completion you can always output the logs from the docker container to a file, e.g. docker logs ansible > ansible-output.log Remove the container docker stop ansible && docker rm ansible If desired, remove the docker-ansible directory. To purge the docker image use docker image rm ansible . Troubleshooting \u00b6 If you encounter permissions or ssh access errors, try setting -v ~/.ssh:/root/.ssh:ro to -v ~/.ssh:/root/win-ssh:ro If ansible struggles to gather facts or stumbles into connection issues, using the ping command will allow you to verify whether the issue is connectivity related (e.g. ssh keys etc) or system specific. Simply ping your host to check the response docker exec -it ansible ansible -m ping 123.456.78.90 . Otherwise you can always attach to the ansible controller shell with docker exec -it ansible /bin/bash and then troubleshoot from there, e.g. try ssh ssh 123.456.78.90 , or check file permissions with ls -alh /root/.ssh/","title":"Docker Ansible"},{"location":"library/tutorials/general/docker-ansible-deployments/#docker-ansible","text":"Docker-Ansible is a project for running an ansible controller in a docker container. This allows the controller to be used on windows and avoids issues with environment specific configuration or possible collisions, making it possible to use ansible playbooks for consistent and reliable deployments on VPS and BareMetal instances. The Kartoza Playbooks is used for company maintained playbooks.","title":"Docker Ansible"},{"location":"library/tutorials/general/docker-ansible-deployments/#prerequisites","text":"Ensure beforehand that you have ssh access to the relevant host, and replace the relevant server details in the host config etc. as outlined in the following commans. By default, Docker-Ansible will attempt to use the ssh configuration files from the host to perform operations.","title":"Prerequisites"},{"location":"library/tutorials/general/docker-ansible-deployments/#procedure","text":"The following example shows bash commands on how to create a new docker-based host. Ensure beforehand that you have ssh access to the host and replace the relevant server details in the host config etc. git clone https://github.com/kartoza/docker-ansible.git cd docker-ansible/ansible rm -r playbooks git clone https://github.com/kartoza/playbooks.git echo 123 .456.78.90 ansible_user = root ansible_private_key_file = /root/.ssh/id_ed25519 > inventory/hosts.ini cd .. docker build . -t ansible docker run -dt -v $PWD /ansible:/ansible \\ -v ~/.ssh:/root/.ssh:ro \\ -e ANSIBLE_CONFIG = /ansible/ansible.cfg \\ --restart = unless-stopped \\ --name ansible ansible docker exec -it ansible ansible-playbook /ansible/playbooks/ubuntu20.04/app/docker-ce.yaml -u iamgroot -k","title":"Procedure"},{"location":"library/tutorials/general/docker-ansible-deployments/#cleanup","text":"Once the task has run to completion you can always output the logs from the docker container to a file, e.g. docker logs ansible > ansible-output.log Remove the container docker stop ansible && docker rm ansible If desired, remove the docker-ansible directory. To purge the docker image use docker image rm ansible .","title":"Cleanup"},{"location":"library/tutorials/general/docker-ansible-deployments/#troubleshooting","text":"If you encounter permissions or ssh access errors, try setting -v ~/.ssh:/root/.ssh:ro to -v ~/.ssh:/root/win-ssh:ro If ansible struggles to gather facts or stumbles into connection issues, using the ping command will allow you to verify whether the issue is connectivity related (e.g. ssh keys etc) or system specific. Simply ping your host to check the response docker exec -it ansible ansible -m ping 123.456.78.90 . Otherwise you can always attach to the ansible controller shell with docker exec -it ansible /bin/bash and then troubleshoot from there, e.g. try ssh ssh 123.456.78.90 , or check file permissions with ls -alh /root/.ssh/","title":"Troubleshooting"},{"location":"library/tutorials/general/git-primer/","text":"Git Primer \u00b6 This tutorial will show you how to use Git to safely implement new features or changes into a project, without any risk of adversely affecting the primary code base, or main branch. We will cover some concepts about git and version control systems to allow suers to get up to speed quickly and start contributing straight away. Basic branching in Git \u00b6 A key function of Git is to function as a \"distributed version control system\", which means that it can be used to track changes in a project across multiple developers. Centralised version control systems typically require an individual to \"check out\" and \"lock\" a resource while it is under development, and then \"check in\" the changes when the resource is ready to be released. By contrast, distributed version control allows multiple to \"fork\" an existing set of resources, and then track backwards through the commit history to see what changes have been made to the resource. A key element of git is \"forking\" and manipulation of \"branches\". Note that this tutorial assumes that users already have a git project setup and ready to use. If you need assistance getting setup, review other resources for Getting started with Git and GitHub , setting up projects on GitLab , migrating existing projects , or simply run git init in a project directory to get going quickly. Monitoring Change in Git \u00b6 Git is a version control system, but its mechanism of operation relies on the process of tracking changes . You could even think of Git primarily as a change monitoring tool, which has a whole host of additional features which make use of the metadata collected during the monitoring operation to provide sophisticated distributed version control. With every new commit, or collection of changes, git collects the differences between the previous commit and the current one, along with some additional metadata. Each commit has a signature, or hash, uniquely identifying it. Later on, this signature can be used to reference the commit and even check for differences between specified commits. Committing Code \u00b6 As highlighted above, Git is a change monitoring tool, but it also needs to be told what files to track the changes on. By default, git won't track changes to any files. Using git add filename will add the file to the \"staging\" area, and git commit -m \"message\" will commit the collection of staged changes to the currently active branch in the repository. In cases where more than one file needs to be added, using a space separated list of files, such as git add file1.ext file2.ext will add all listed files to the staging area. To add all files (not matched by .gitignore ) to the staging area at once, simply use git add -A . Git Branches \u00b6 Commits track these changes in sequence to each other. This is what enables git as such a powerful method of distributed version control, and can also be effectively leveraged to provide a method of branching , whereby certain changes are developed in isolation to the rest of the project. Git uses branches by default, although new projects are simply created with a single default, or main , branch. A chain of commits in a single branch Repository Creating Branches \u00b6 Creating a new branch can be done with the command git checkout -b branch-name . The -b , or branch, flag indicates that git should create a new branch with the specified name. The base commit of the branch will simply reference the currently active HEAD commit. Future commits to the main branch will no longer affect the new branch. A new git branch is simply creating a \"forked\" chain, using a specific commit record as the base Performing a git commit with a new branch checked out creates a distinct history from parallel branches This should clearly illustrate how branches keep changes isolated between them, allowing changes to be made to the code without affecting the other branches. Viewing Branches \u00b6 Checking the available branches in a repository is as simple as git branch , which will print out a list of available branches and indicate the active branch with an asterisk. GitHub provides a drop-down menu with the available branches Branches and resources within branches can also be accessed via URL Changing Branches \u00b6 Commits and other git commands are typically going to be executed on the active branch. To switch between branches, simply use git checkout branch-name . In some cases, you may have uncommitted changes which may get lost when switching between branches. To prevent data loss in these instances, git includes the stash feature. And then some \u00b6 Git is incredibly powerful (and as a result, rather complex). A common use case, however, might be the merging of changes from a branch back into the main branch of the project. The git merge command is designed for exactly this, and it's typical usage follows a simple workflow. Simply switch the active branch to the branch it is desired that the changes are merged into, e.g. git checkout main Then use git merge branch-name to merge the changes from branch-name into the main branch. Git supports multiple branches, and creating branches from other branches, so it's perfectly feasible that some long lived branches might be kept around for certain purposes, whilst others are merged into other branches, and then discarded. A Git repository might include feature branches kept in isolation, or it may merge changes from a branch back into the main branch The \"HEAD\" reference in git is simply pointing to a specific commit, which will often be designated to the currently active branch. There's all sorts of advanced functionality available for managing the repository, such as remote repository management, cherry picking, and history modifications... but very often users simply need a way to manage simple changes in an isolated manner, and branches are a great way to do that. For the more advanced functionalities, additional tools can help simplify the management and deployment of Git repositories. Conflict resolution, Rebase, History, Squashing, and Stashing \u00b6 These are terms for all that \"advanced functionality\" that was just mentioned. When merging changes from one branch into another, or switching between branches with committed and uncommitted changes, there are a number of scenarios which can occur. This introduces a plethora of git functionalities (and jargon) which give git it's superpowered reputation and a fair number of jokes about it's complexity. For the most part, however, the concepts are actually simple... it's the execution that can be complicated. Over the years, many tools and platforms have produced more efficient ways to handle these scenarios in efficient and reliable ways, so they're less of a pain point, but we'll cover them here at a high level so that when they are encountered, you'll know what to do with them \ud83d\ude09. If multiple individuals make changes to the same file, in the same place, a conflict can occur - that means that git cannot automatically resolve what the correct code is that should be injected into the resource, and manual conflict resolution must be done where a developer tells git which lines to keep, which to remove, and which to add to a new commit to patch things up to standard again. Sometimes a new set of features should be \"rebased\" - that is switching the \"base commit\" that it was forked from (often to the most recent main commit), and the developer can resolve any minor conflicts before asking for a code review from upstream developers etc. It's also capable of doing this in an interactive way, allowing developers to pick which commmits to keep when you have a git history full of noise, mistakes or other issues. There are also a great many ways to rewrite, or even migrate, git history... Remember that git tracks changes , which can, in fact, lead to bloat. Another way to clean up the history is to \"squash\" commits - so noisy or erroneous changes can be excluded from the history. This often makes things easier for reviewers to understand and cleans up bloat. Finally, git has a feature called \"stashing\" which allows developers to temporarily store changes in a \"stash\" before committing them to git. This is useful when a developer is working on changes that are not ready for committing, and needs to be able to revert to a previous state, change branches, or pull new commits from the upstream repository into their current branch. Essentially the \"stash\" is a kind of temporary or background commit that does not form a part of the git history, and allows users to avoid conflicts and prevent data loss. Releasing Changes \u00b6 Once you have your changes committed to your branch, you can create a \"featured checkpoint\" in your project using a git tag with the -a flag to add an annotation. git tag -a v0.1-my-changes -m \"my changes for v0.1\" On existing projects, you may want to review the available tags for a project using git tag -l before you decide on a tagging convention. Of course tags will only make the source code available to other developers, but a more sophisticated method of distributing your changes would be to create a release which might include compiled assets. If you're eager to get started with Git, be sure to check out what others are building , or contribute to ongoing open source initiatives . PRs, MRs, Issues, Releases, Packages, CI/CD, and GitOp(tion)s Galore \u00b6 Git itself is a version control utility... and a really great one at that. What it doesn't do are things like project management, issue tracking, bug reports, file distribution and more. There are, however, a lot of platforms that fill this gap and offer a great suite of tools for managing and deploying Git repositories alongside these other features, like GitHub, GitLab, BitBucket, or even self hosted systems like Gitea. The key elements are the \"Pull Requests\" and \"Merge Requests\". These are essentially the same thing conceptually - You are flagging to the \"upstream\" repository managers that you originally forked from that you have changes which you believe would be beneficial to integrate into another branch of the repository. Platforms like GitHub say \"Pull Request\", because the first action you would perform would be to get your changes pulled into the upstream repository. Platforms like GitLab say \"Merge Request\", because the last action you would perform would be to merge these changes into the upstream branch (typically the default branch of main or develop , but various workflows exist for feature branches and more). TL;DR \u00b6 Git commandline seem a bit confusing for you? Good news is once you understand what it's doing under the hood, how you get it done should be less of an issue. I definitely recommend the super-duper-next-level-ultra-awesome GitLens for VSCode . Conclusion \u00b6 What? You made it to the end? I don't believe you I think you cheated and skipped the rest of the content. But if you really did make it all the way here from start to finish I am very proud. You deserve a present. Here, have a carrot... \ud83e\udd55","title":"Git Primer"},{"location":"library/tutorials/general/git-primer/#git-primer","text":"This tutorial will show you how to use Git to safely implement new features or changes into a project, without any risk of adversely affecting the primary code base, or main branch. We will cover some concepts about git and version control systems to allow suers to get up to speed quickly and start contributing straight away.","title":"Git Primer"},{"location":"library/tutorials/general/git-primer/#basic-branching-in-git","text":"A key function of Git is to function as a \"distributed version control system\", which means that it can be used to track changes in a project across multiple developers. Centralised version control systems typically require an individual to \"check out\" and \"lock\" a resource while it is under development, and then \"check in\" the changes when the resource is ready to be released. By contrast, distributed version control allows multiple to \"fork\" an existing set of resources, and then track backwards through the commit history to see what changes have been made to the resource. A key element of git is \"forking\" and manipulation of \"branches\". Note that this tutorial assumes that users already have a git project setup and ready to use. If you need assistance getting setup, review other resources for Getting started with Git and GitHub , setting up projects on GitLab , migrating existing projects , or simply run git init in a project directory to get going quickly.","title":"Basic branching in Git"},{"location":"library/tutorials/general/git-primer/#monitoring-change-in-git","text":"Git is a version control system, but its mechanism of operation relies on the process of tracking changes . You could even think of Git primarily as a change monitoring tool, which has a whole host of additional features which make use of the metadata collected during the monitoring operation to provide sophisticated distributed version control. With every new commit, or collection of changes, git collects the differences between the previous commit and the current one, along with some additional metadata. Each commit has a signature, or hash, uniquely identifying it. Later on, this signature can be used to reference the commit and even check for differences between specified commits.","title":"Monitoring Change in Git"},{"location":"library/tutorials/general/git-primer/#committing-code","text":"As highlighted above, Git is a change monitoring tool, but it also needs to be told what files to track the changes on. By default, git won't track changes to any files. Using git add filename will add the file to the \"staging\" area, and git commit -m \"message\" will commit the collection of staged changes to the currently active branch in the repository. In cases where more than one file needs to be added, using a space separated list of files, such as git add file1.ext file2.ext will add all listed files to the staging area. To add all files (not matched by .gitignore ) to the staging area at once, simply use git add -A .","title":"Committing Code"},{"location":"library/tutorials/general/git-primer/#git-branches","text":"Commits track these changes in sequence to each other. This is what enables git as such a powerful method of distributed version control, and can also be effectively leveraged to provide a method of branching , whereby certain changes are developed in isolation to the rest of the project. Git uses branches by default, although new projects are simply created with a single default, or main , branch. A chain of commits in a single branch Repository","title":"Git Branches"},{"location":"library/tutorials/general/git-primer/#creating-branches","text":"Creating a new branch can be done with the command git checkout -b branch-name . The -b , or branch, flag indicates that git should create a new branch with the specified name. The base commit of the branch will simply reference the currently active HEAD commit. Future commits to the main branch will no longer affect the new branch. A new git branch is simply creating a \"forked\" chain, using a specific commit record as the base Performing a git commit with a new branch checked out creates a distinct history from parallel branches This should clearly illustrate how branches keep changes isolated between them, allowing changes to be made to the code without affecting the other branches.","title":"Creating Branches"},{"location":"library/tutorials/general/git-primer/#viewing-branches","text":"Checking the available branches in a repository is as simple as git branch , which will print out a list of available branches and indicate the active branch with an asterisk. GitHub provides a drop-down menu with the available branches Branches and resources within branches can also be accessed via URL","title":"Viewing Branches"},{"location":"library/tutorials/general/git-primer/#changing-branches","text":"Commits and other git commands are typically going to be executed on the active branch. To switch between branches, simply use git checkout branch-name . In some cases, you may have uncommitted changes which may get lost when switching between branches. To prevent data loss in these instances, git includes the stash feature.","title":"Changing Branches"},{"location":"library/tutorials/general/git-primer/#and-then-some","text":"Git is incredibly powerful (and as a result, rather complex). A common use case, however, might be the merging of changes from a branch back into the main branch of the project. The git merge command is designed for exactly this, and it's typical usage follows a simple workflow. Simply switch the active branch to the branch it is desired that the changes are merged into, e.g. git checkout main Then use git merge branch-name to merge the changes from branch-name into the main branch. Git supports multiple branches, and creating branches from other branches, so it's perfectly feasible that some long lived branches might be kept around for certain purposes, whilst others are merged into other branches, and then discarded. A Git repository might include feature branches kept in isolation, or it may merge changes from a branch back into the main branch The \"HEAD\" reference in git is simply pointing to a specific commit, which will often be designated to the currently active branch. There's all sorts of advanced functionality available for managing the repository, such as remote repository management, cherry picking, and history modifications... but very often users simply need a way to manage simple changes in an isolated manner, and branches are a great way to do that. For the more advanced functionalities, additional tools can help simplify the management and deployment of Git repositories.","title":"And then some"},{"location":"library/tutorials/general/git-primer/#conflict-resolution-rebase-history-squashing-and-stashing","text":"These are terms for all that \"advanced functionality\" that was just mentioned. When merging changes from one branch into another, or switching between branches with committed and uncommitted changes, there are a number of scenarios which can occur. This introduces a plethora of git functionalities (and jargon) which give git it's superpowered reputation and a fair number of jokes about it's complexity. For the most part, however, the concepts are actually simple... it's the execution that can be complicated. Over the years, many tools and platforms have produced more efficient ways to handle these scenarios in efficient and reliable ways, so they're less of a pain point, but we'll cover them here at a high level so that when they are encountered, you'll know what to do with them \ud83d\ude09. If multiple individuals make changes to the same file, in the same place, a conflict can occur - that means that git cannot automatically resolve what the correct code is that should be injected into the resource, and manual conflict resolution must be done where a developer tells git which lines to keep, which to remove, and which to add to a new commit to patch things up to standard again. Sometimes a new set of features should be \"rebased\" - that is switching the \"base commit\" that it was forked from (often to the most recent main commit), and the developer can resolve any minor conflicts before asking for a code review from upstream developers etc. It's also capable of doing this in an interactive way, allowing developers to pick which commmits to keep when you have a git history full of noise, mistakes or other issues. There are also a great many ways to rewrite, or even migrate, git history... Remember that git tracks changes , which can, in fact, lead to bloat. Another way to clean up the history is to \"squash\" commits - so noisy or erroneous changes can be excluded from the history. This often makes things easier for reviewers to understand and cleans up bloat. Finally, git has a feature called \"stashing\" which allows developers to temporarily store changes in a \"stash\" before committing them to git. This is useful when a developer is working on changes that are not ready for committing, and needs to be able to revert to a previous state, change branches, or pull new commits from the upstream repository into their current branch. Essentially the \"stash\" is a kind of temporary or background commit that does not form a part of the git history, and allows users to avoid conflicts and prevent data loss.","title":"Conflict resolution, Rebase, History, Squashing, and Stashing"},{"location":"library/tutorials/general/git-primer/#releasing-changes","text":"Once you have your changes committed to your branch, you can create a \"featured checkpoint\" in your project using a git tag with the -a flag to add an annotation. git tag -a v0.1-my-changes -m \"my changes for v0.1\" On existing projects, you may want to review the available tags for a project using git tag -l before you decide on a tagging convention. Of course tags will only make the source code available to other developers, but a more sophisticated method of distributing your changes would be to create a release which might include compiled assets. If you're eager to get started with Git, be sure to check out what others are building , or contribute to ongoing open source initiatives .","title":"Releasing Changes"},{"location":"library/tutorials/general/git-primer/#prs-mrs-issues-releases-packages-cicd-and-gitoptions-galore","text":"Git itself is a version control utility... and a really great one at that. What it doesn't do are things like project management, issue tracking, bug reports, file distribution and more. There are, however, a lot of platforms that fill this gap and offer a great suite of tools for managing and deploying Git repositories alongside these other features, like GitHub, GitLab, BitBucket, or even self hosted systems like Gitea. The key elements are the \"Pull Requests\" and \"Merge Requests\". These are essentially the same thing conceptually - You are flagging to the \"upstream\" repository managers that you originally forked from that you have changes which you believe would be beneficial to integrate into another branch of the repository. Platforms like GitHub say \"Pull Request\", because the first action you would perform would be to get your changes pulled into the upstream repository. Platforms like GitLab say \"Merge Request\", because the last action you would perform would be to merge these changes into the upstream branch (typically the default branch of main or develop , but various workflows exist for feature branches and more).","title":"PRs, MRs, Issues, Releases, Packages, CI/CD, and GitOp(tion)s Galore"},{"location":"library/tutorials/general/git-primer/#tldr","text":"Git commandline seem a bit confusing for you? Good news is once you understand what it's doing under the hood, how you get it done should be less of an issue. I definitely recommend the super-duper-next-level-ultra-awesome GitLens for VSCode .","title":"TL;DR"},{"location":"library/tutorials/general/git-primer/#conclusion","text":"What? You made it to the end? I don't believe you I think you cheated and skipped the rest of the content. But if you really did make it all the way here from start to finish I am very proud. You deserve a present. Here, have a carrot... \ud83e\udd55","title":"Conclusion"},{"location":"library/tutorials/general/google-meet/","text":"Content \u00b6","title":"Content"},{"location":"library/tutorials/general/google-meet/#content","text":"","title":"Content"},{"location":"library/tutorials/general/jitsi/","text":"Content \u00b6","title":"Content"},{"location":"library/tutorials/general/jitsi/#content","text":"","title":"Content"},{"location":"library/tutorials/general/mkdocs-pdf/","text":"MkDocs PDF \u00b6 Serving a local clone of this documentation with docker is as simple as docker run --rm -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material . This process walks through attempting to setup an environment with Docker that will produce PDF documentation for a MkDocs site with A MkDocs-Material Theme (Like this one). Docker environment \u00b6 Create a dockerfile with the relevant dependencies in line with the mkdocs-material docs and the mkdocs-pdf-export-plugin . FROM squidfunk/mkdocs-material:8.2.15 # RUN pip install mkdocs-pdf-export-plugin # Thanks to: # https://stackoverflow.com/questions/71372066/docker-fails-to-install-cffi-with-python3-9-alpine-in-dockerfile # https://github.com/Kozea/WeasyPrint/issues/699 RUN apk add --update --no-cache --virtual .tmp-build-deps \\ gcc libc-dev linux-headers \\ && apk add musl-dev jpeg-dev zlib-dev libffi-dev cairo-dev pango-dev gdk-pixbuf RUN python -m pip install --upgrade pip && \\ python -m pip install mkdocs-pdf-export-plugin # Set working directory WORKDIR /docs # Expose MkDocs development server port EXPOSE 8000 # Start development server by default ENTRYPOINT [\"mkdocs\"] CMD [\"serve\", \"--dev-addr=0.0.0.0:8000\"] Now create the custom mkdocs-material docker image with the command docker build -t my-mkdocs . . Export Single PDF \u00b6 To build the updated documentation and produce the output pdf, edit the mkdocs.yml file to include the plugin with the \"combined\" option set to true: plugins: - search - pdf-export: verbose: true media_type: print combined: true combined_output_path: pdf/TheKartozaHandbook.pdf Then use the following command to build the docs docker run --rm -it -v ${PWD}:/docs my-mkdocs build PDF Export Plugin \u00b6 The PDF export plugin can also be used to add a \"download pdf\" for each page. To try this out, edit the mkdocs.yml file to include the plugin: plugins: - search - pdf-export Now you can run the documentation with the command: docker run --rm -p 8000:8000 -v ${PWD}:/docs my-mkdocs Note that setting the \"combined\" option to true when service the documentation with the plugin will automatically point all download links to the collated file and individual page exports will not be available. This docker file takes rather a long time to start up... The docker logs will hang while the documentation is built. This is much slower with the PDF export plugin and using the default mkdocs-material image and configuration will be much faster for simple site builds. The expected docker logs output might be as follows: warnings.warn( INFO - Cleaning site directory INFO - The following pages exist in the docs directory, but are not included in the \"nav\" configuration: - development/conventions/dev_processes.md - development/conventions/git.md - development/conventions/ides.md - development/conventions/project_processes.md - development/environments/links.md - development/environments/vscode/extension_install.md - development/environments/vscode/links.md - development/technologies/frameworks.md - development/technologies/languages.md - devops/infrastructure/personal_infrastructure.md - devops/infrastructure/rancher-k3s-single-node.md - devops/security/links.md - library/cheatsheets/bash.md - library/cheatsheets/postgresql.md - library/media/newsletters.md - library/tutorials/general/index.md - library/tutorials/general/google-meet.md - library/tutorials/general/jitsi.md - library/tutorials/general/zoom.md - library/tutorials/links/index.md - library/tutorials/qgis/index.md After a long wait period, the docker log should let you know the system is running and you can access the site on your local machine from the URL http://127.0.0.1:8000 INFO - Documentation built in 224.82 seconds INFO - [11:40:10] Watching paths for changes: 'docs', 'mkdocs.yml' INFO - [11:40:10] Serving on http://0.0.0.0:8000/ Once it's built it should include a pdf export button at the top of each page. TODO \u00b6 Add theming/ customization Incorporate into GitHub Pages site and actions Add static collated pdf version (and download link) to published docs","title":"MkDocs PDF"},{"location":"library/tutorials/general/mkdocs-pdf/#mkdocs-pdf","text":"Serving a local clone of this documentation with docker is as simple as docker run --rm -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material . This process walks through attempting to setup an environment with Docker that will produce PDF documentation for a MkDocs site with A MkDocs-Material Theme (Like this one).","title":"MkDocs PDF"},{"location":"library/tutorials/general/mkdocs-pdf/#docker-environment","text":"Create a dockerfile with the relevant dependencies in line with the mkdocs-material docs and the mkdocs-pdf-export-plugin . FROM squidfunk/mkdocs-material:8.2.15 # RUN pip install mkdocs-pdf-export-plugin # Thanks to: # https://stackoverflow.com/questions/71372066/docker-fails-to-install-cffi-with-python3-9-alpine-in-dockerfile # https://github.com/Kozea/WeasyPrint/issues/699 RUN apk add --update --no-cache --virtual .tmp-build-deps \\ gcc libc-dev linux-headers \\ && apk add musl-dev jpeg-dev zlib-dev libffi-dev cairo-dev pango-dev gdk-pixbuf RUN python -m pip install --upgrade pip && \\ python -m pip install mkdocs-pdf-export-plugin # Set working directory WORKDIR /docs # Expose MkDocs development server port EXPOSE 8000 # Start development server by default ENTRYPOINT [\"mkdocs\"] CMD [\"serve\", \"--dev-addr=0.0.0.0:8000\"] Now create the custom mkdocs-material docker image with the command docker build -t my-mkdocs . .","title":"Docker environment"},{"location":"library/tutorials/general/mkdocs-pdf/#export-single-pdf","text":"To build the updated documentation and produce the output pdf, edit the mkdocs.yml file to include the plugin with the \"combined\" option set to true: plugins: - search - pdf-export: verbose: true media_type: print combined: true combined_output_path: pdf/TheKartozaHandbook.pdf Then use the following command to build the docs docker run --rm -it -v ${PWD}:/docs my-mkdocs build","title":"Export Single PDF"},{"location":"library/tutorials/general/mkdocs-pdf/#pdf-export-plugin","text":"The PDF export plugin can also be used to add a \"download pdf\" for each page. To try this out, edit the mkdocs.yml file to include the plugin: plugins: - search - pdf-export Now you can run the documentation with the command: docker run --rm -p 8000:8000 -v ${PWD}:/docs my-mkdocs Note that setting the \"combined\" option to true when service the documentation with the plugin will automatically point all download links to the collated file and individual page exports will not be available. This docker file takes rather a long time to start up... The docker logs will hang while the documentation is built. This is much slower with the PDF export plugin and using the default mkdocs-material image and configuration will be much faster for simple site builds. The expected docker logs output might be as follows: warnings.warn( INFO - Cleaning site directory INFO - The following pages exist in the docs directory, but are not included in the \"nav\" configuration: - development/conventions/dev_processes.md - development/conventions/git.md - development/conventions/ides.md - development/conventions/project_processes.md - development/environments/links.md - development/environments/vscode/extension_install.md - development/environments/vscode/links.md - development/technologies/frameworks.md - development/technologies/languages.md - devops/infrastructure/personal_infrastructure.md - devops/infrastructure/rancher-k3s-single-node.md - devops/security/links.md - library/cheatsheets/bash.md - library/cheatsheets/postgresql.md - library/media/newsletters.md - library/tutorials/general/index.md - library/tutorials/general/google-meet.md - library/tutorials/general/jitsi.md - library/tutorials/general/zoom.md - library/tutorials/links/index.md - library/tutorials/qgis/index.md After a long wait period, the docker log should let you know the system is running and you can access the site on your local machine from the URL http://127.0.0.1:8000 INFO - Documentation built in 224.82 seconds INFO - [11:40:10] Watching paths for changes: 'docs', 'mkdocs.yml' INFO - [11:40:10] Serving on http://0.0.0.0:8000/ Once it's built it should include a pdf export button at the top of each page.","title":"PDF Export Plugin"},{"location":"library/tutorials/general/mkdocs-pdf/#todo","text":"Add theming/ customization Incorporate into GitHub Pages site and actions Add static collated pdf version (and download link) to published docs","title":"TODO"},{"location":"library/tutorials/general/zoom/","text":"Content \u00b6","title":"Content"},{"location":"library/tutorials/general/zoom/#content","text":"","title":"Content"},{"location":"library/tutorials/links/","text":"Tutorial Links \u00b6 Links to third party and external tutorials and learning resources","title":"Tutorial Links"},{"location":"library/tutorials/links/#tutorial-links","text":"Links to third party and external tutorials and learning resources","title":"Tutorial Links"},{"location":"library/tutorials/qgis/","text":"QGIS Tutorials \u00b6 QGIS Tutorials","title":"QGIS Tutorials"},{"location":"library/tutorials/qgis/#qgis-tutorials","text":"QGIS Tutorials","title":"QGIS Tutorials"}]}